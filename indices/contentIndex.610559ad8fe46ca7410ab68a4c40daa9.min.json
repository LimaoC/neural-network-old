{"/":{"title":"Neural Network","content":"\nHello, and welcome to my neural network! This is where I store my second brain - filled with notes from my mathematics and computer science degrees.\n\nBelow is the structure of the network. Each top-level (generally) represents a broad discipline/field and has tags to further subdivide the notes. The links below will take you to all the notes belonging to that particular discipline or tag.\n\n/[mathematics](/mathematics) \\\n├─ [formal logic](/tags/formal-logic) \\\n/[statistics](/statistics) \\\n├─ [probability](/tags/probability)\n\n\u003e Tip: you can use `ctrl + k` to quick search the entire network of notes.\n\n## Contributing\nIf you spot any mistakes, or have any suggestions, feel free to:\n- create an issue or pull request over at the [Github repo](https://github.com/LimaoC/neural-network), or\n- click on the \"edit source\" button on any of the pages to go to the source file directly.\n\n## Local Setup\nHTTPS:\n```\ngit clone https://github.com/LimaoC/neural-network.git\ncd neural-network\nmake  # run local web server\n```\n\nSSH:\n```\ngit clone git@github.com:LimaoC/neural-network.git\ncd neural-network\nmake  # run local web server\n```\n\n### Obsidian Vault\nIf you'd prefer to use the notes locally with [Obsidian](https://obsidian.md/) instead of the web version, you can clone the repository open up the `content` directory as an Obsidian vault (with working links).\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/mathematics/gamma-function":{"title":"Gamma Function","content":"\n## Definition\nThe *gamma function* is an extension of the factorial function to complex numbers, and is defined for all complex numbers except for non-positive integers.\n\nFor positive integers $n$,\n$$\\Gamma(n) = (n - 1)!,$$\nand for complex numbers $z$ with a positive real part,\n$$\\Gamma(z) = \\int_0^\\infty x^{z-1} e^{-x} \\thinspace dx.$$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/mathematics/lambda-calculus":{"title":"Lambda Calculus","content":"\n## Definition\n*Lambda calculus* (also written as $\\lambda$-calculus) is a formal system for expressing computations based on function abstraction (defining and expressing $\\lambda$-terms, also called $\\lambda$-expressions) and function application (applying functions to arguments).\n\n## Lambda Terms ($\\lambda$-terms)\nA *$\\lambda$-term* is a valid $\\lambda$-calculus expression. The set of all lambda terms, $\\Lambda$, is recursively generated as follows:\n- A variable $x$ is itself a $\\lambda$-term\n- If $t$ is a $\\lambda$-term and $x$ is a variable, then $(\\lambda x.t)$ is a $\\lambda$-term, also called an abstraction. $(\\lambda x.t)$ denotes an anonymous function that takes an input $x$ and returns $t$.\n- If $t$ and $s$ are $\\lambda$-terms, then $(t \\thinspace s)$ is a $\\lambda$-term, also called an application. $(t \\thinspace s)$ denotes the application of a function $t$ to an input $s$.\n\nThere are some rules for evaluating $\\lambda$-expressions:\n1. Application has higher precedence than abstraction. $\\lambda x. A \\thinspace B$ means $\\lambda x. (A \\thinspace B)$ and not $(\\lambda x.A)B$\n2. Application is left-associative. $A \\thinspace B \\thinspace C$ means $(A \\thinspace B) \\thinspace C$ and not $A \\thinspace (B \\thinspace C)$\n3. Abstraction is right-associative. $\\lambda x. A \\thinspace \\lambda y.B$ means $(\\lambda x . (A \\thinspace \\lambda y . B))$ and not $(\\lambda x . A)(\\lambda y . B)$\n\nWe are only allowed to use univariate functions, but we can simulate multivariate functions by \"chaining\" single-variate functions like so:\n$$\\lambda x.(\\lambda y.(\\lambda z.x+y+z)),$$\nwhich we can write in short-form notation:\n$$\\lambda xyz.x + y + z$$\n\nA *free variable* in a $\\lambda$-expression is one that is not bounded by an abstraction. The set of free variables $\\mathcal{F}(r)$ in an expression $r \\in \\Lambda$ can be recursively generated as follows:\n- $\\mathcal{F}(x) = \\lbrace x \\rbrace$\n- $\\mathcal{F}(\\lambda x.t) = \\mathcal{F}(t) - \\lbrace x \\rbrace$\n- $\\mathcal{F}(s \\thinspace t) = \\mathcal{F}(s) \\cup \\mathcal{F}(t)$ for $s, t \\in \\Lambda$\n\nA *combinator* is a $\\lambda$-expression with no free variables; they are named as such as these expressions serve only to combine arguments.\n\nA term that cannot be reduced any further is said to be in $\\beta$-normal form. It can be thought of as a fully executed functional program. If a term cannot be reduced to a $\\beta$-normal form, it is said to be divergent.\n\n## Reduction Operations\nThere are two reduction operations that can be performed on $\\lambda$-terms:\n- An *$\\alpha$-conversion*, denoted by $(\\lambda x.M[ x]) \\to (\\lambda y.M[y])$, where we rename variables to avoid name collisions.\n- A *$\\beta$-reduction*, denoted by $((\\lambda x.M)E) \\to (M[x := E])$, where we replace bound variables with the argument expression in the body of the abstraction.\n\nTwo $\\lambda$-expressions that are identical after $\\alpha$-conversion are called *$\\alpha$-equivalent*.\n\n## Haskell Ordering\nA *reducible expression* or *redex* is any expression to which a $\\beta$-reduction can be immediately applied. When multiple reducible expressions are present, choose the left-most redex that is not in the body of a lambda abstraction, i.e. do the outermost and leftmost reduction first.\n\n## Boolean Logic\nLambda calculus can also be used to model boolean logic. One possible formulation is listed below:\n- $\\text{True} := \\lambda x . \\lambda y . x$\n- $\\text{False} := \\lambda x . \\lambda y . y$\n- $\\text{And} := \\lambda p . \\lambda q . p \\thinspace q \\thinspace p$\n- $\\text{Or} := \\lambda p . \\lambda q . p \\thinspace p \\thinspace q$\n- $\\text{Not} := \\lambda p . p \\thinspace \\text{True} \\thinspace \\text{False}$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/acceptance-rejection-method":{"title":"Acceptance Rejection Method","content":"\n## Definition\nThe *acceptance-rejection method* is a method of generating [random variables](statistics/random-variable.md) from a given distribution with [pdf](statistics/probability-density-function.md) $f$.\n\n## Method\nFirst, pick a *proposal* pdf $g$ such that:\n- $g$ is easy to sample from,\n- there is a constant $C$ such that $Cg(x) \\geq f(x)$ for all $x$; that is, $Cg(x)$ \"encloses\" the pdf $f$.\n\nThen the method is as follows:\n1. Generate $X \\sim g$.\n2. Generate $Y \\sim \\mathcal{U}(0, Cg(X))$.\n3. If $Y \\leq f(X)$, return $Z = X$. Otherwise, return to step 1.\n\nThe random variable $X$ returned by the algorithm has pdf $f$.\n\n## Efficiency\nThe *efficiency* of an acceptance-rejection method is defined as\n$$\\mathbb{P}((X, Y) \\text{ is accepted}) = \\frac{\\text{Area under } f}{\\text{Area under } Cg} = \\frac{1}{C}.$$\nWe would like to maximize the efficiency $1/C$ (i.e. $C$ should be close to $1$), which means choosing a proposal $g$ that is close to $f$. This is to minimize the number of rejections we have, which results in fewer iterations of the algorithm.\n\n## See Also\n- [Inverse Transform Method](statistics/inverse-transform-method.md)\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/bayes-theorem":{"title":"Bayes' Theorem","content":"\n## Definition\nLet $A$ and $B$ be arbitrary [events](statistics/event.md) such that $\\mathbb{P}(A) \u003e 0$ and $0 \u003c \\mathbb{P}(B) \u003c 1$. Then\n$$\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)} = \\frac{\\mathbb{P}(A|B)\\mathbb{P}(B)}{\\mathbb{P}(A)},$$\nusing the definition of [conditional probability](statistics/conditional-probability.md) twice and the [Law of Total Probability](statistics/law-of-total-probability.md).\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/bernoulli-distribution":{"title":"Bernoulli Distribution","content":"\n## Definition\nThe *Bernoulli distribution* is the discrete probability distribution with parameter $p$ (success probability) that takes the value 1 with probability $p$ and the value 0 with probability $1 - p$.\n\nThe Bernoulli distribution is a special case of the [binomial distribution](statistics/binomial-distribution.md) with $n = 1$.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a *Bernoulli [random variable](statistics/random-variable.md)* with success probability $p$; that is, $X \\sim \\text{Ber}(p)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\begin{cases}\np, \u0026\u0026 \\text{if } x = 1 \\\\\n1 - p, \u0026\u0026 \\text{if } x = 0 \\\\\n0, \u0026\u0026 \\text{otherwise}.\n\\end{cases}$$\nand [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = \\begin{cases}\n0, \u0026\u0026 \\text{if } x \u003c 0 \\\\\n1 - p, \u0026\u0026 \\text{if } 0 \\leq x \u003c 1 \\\\\n1, \u0026\u0026 \\text{if } x \u003e= 1.\n\\end{cases}$$\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = 0 \\cdot (1 - p) + 1 \\cdot p = p.$$\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\begin{align*}\n\\text{Var}(X) \u0026= \\mathbb{E}(X^2) - (\\mathbb{E}X)^2 \\\\\n\u0026= (0^2 \\cdot (1 - p) + 1^2 \\cdot p) - p^2 \\\\\n\u0026= p - p^2 = p(1 - p).\n\\end{align*}$$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/binomial-distribution":{"title":"Binomial Distribution","content":"\n## Definition\nThe *binomial distribution* with parameters $n$ (number of trials) and $p$ (success probability) is the discrete probability distribution of the number of successes in $n$ independent experiments, each taking on the value 1 with probability $p$ and the value 0 with probability $1 - p$.\n\nThe [Bernoulli distribution](statistics/bernoulli-distribution.md) is a special case of the binomial distribution with $n = 1$.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a binomial [random variable](statistics/random-variable.md) with $n$ trials and success probability $p$; that is, $X \\sim \\text{Bin}(n, p)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\binom{n}{x} p^x (1 - p)^{n-x}$$\nfor a non-negative integer $x$ (number of successes), and $0$ otherwise. The quantity\n$$\\binom{n}{x} = \\frac{n!}{x!(n-x)!}$$\nis the *binomial coefficient* *\\[link needed\\]*. Note that omitting the binomial coefficient gives us the pmf of a Bernoulli random variable; the binomial coefficient gives us the number of ways in which we can arrange $x$ successes and $n - x$ failures.\n$X$ has [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = \\sum_{k=0}^{\\lfloor k \\rfloor} \\binom{n}{k} p^k (1 - p)^{n-k}.$$\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = np,$$\nwhich follows from applying linearity of expectation to the fact that $X$ is equivalent to the sum of $n$ Bernoulli random variables each with expectation $p$.\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = np(1 - p),$$\nwhich follows from the fact that the variance of the sum of independent random variables is the sum of the variances *\\[link needed\\]*.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/booles-inequality":{"title":"Boole's Inequality","content":"\n## Definition\nFor any [events](statistics/event.md) $A_1, A_2, \\dots$, we have\n$$\\mathbb{P}\\left(\\bigcup_i A_i\\right) \\leq \\sum_i \\mathbb{P}(A_i).$$\nThat is, the probability that at least one of the events occurs is less than or equal to the sum of the probabilities of the individual events.\n\n## Proof\nWe proceed by induction. The $n = 1$ case holds, since $\\mathbb{P}(A_1) \\leq \\mathbb{P}(A_1)$. Then assume the $n = k$ case holds; that is,\n$$\\mathbb{P}\\left(\\bigcup_{i=1}^k A_i\\right) \\leq \\sum_{i=1}^k \\mathbb{P}(A_i).$$\nUsing $\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)$, \n$$\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) = \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) - \\mathbb{P}\\left(\\left(\\bigcup_{i=1}^n A_i \\right) \\bigcap A_{k+1} \\right),$$\nand since $\\mathbb{P}(E) \\geq 0$ for any event $E$ ([first axiom of probability](statistics/probability-measure.md)),\n$$\\begin{align*}\n\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) \u0026\\leq \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026\\leq \\sum_{i=1}^k \\mathbb{P}(A_i) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026= \\sum_{i=1}^{k+1} \\mathbb{P}(A_i).\n\\end{align*}$$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/conditional-probability":{"title":"Conditional Probability","content":"\n## Definition\nThe [event](statistics/event.md) that $A$ occurs, given that we know $B$ has occurred, is denoted $A | B$. We have\n$$\\mathbb{P}(A | B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)},$$\nwhere $\\mathbb{P}(B \u003e 0)$. \n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/cumulative-distribution-function":{"title":"Cumulative Distribution Function","content":"\n## Definition\nIf $X$ is an arbitrary [random variable](statistics/random-variable.md), then the function\n$$F(x) = \\mathbb{P}(X \\leq x)$$\nis the *(cumulative) distribution function* of $X$. It is often denoted $F_X(x)$.\n\n## Properties\nLet $X$ be a random variable. Then the distribution function $F$ has the following properties:\n1. $F(x) \\to 0$ as $x \\to -\\infty$.\n2. $F(x) \\to 1$ as $x \\to \\infty$.\n3. $F$ is an increasing function; that is $x \u003e y \\implies F(x) \\geq F(y)$.\n4. $F$ is continuous from the right; that is, for all $x$, $F(x + h) \\to F(x)$ as $h \\downarrow 0$ (limit from above).\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/de-morgans-laws":{"title":"De Morgan's Laws","content":"\n## Definition\nLet $\\lbrace A_i \\rbrace$ be a collection of [events](statistics/event.md). Then\n$$\\left(\\bigcup_i A_i\\right)^c = \\bigcap_i A_i^c \\quad\\text{and}\\quad\\left(\\bigcap_i A_i\\right)^c = \\bigcup_i A_i^c.$$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/disjoint-event":{"title":"Disjoint Event","content":"\n## Definition\nIf $A$ and $B$ are two [events](statistics/event.md) such that they share no outcomes in common, they are said to be *disjoint*, that is $A \\cap B = \\varnothing$. More generally, $A_1, A_2, \\dots$ is said to be *disjoint* if each pair of events $(A_i, A_j$) with $i \\neq j$, is disjoint.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/event":{"title":"Event","content":"\n## Definition\nAn *event* is any subset of outcomes; that is, any subset of the [sample space](statistics/sample-space.md) $\\Omega$.\n\nIf $A$ is an event, then $A$ complement, denoted $A^c$, is the event that $A$ does not occur.\n\nLet $\\lbrace A_i \\rbrace$ be a collection of events. \\\nThe *union* of $\\lbrace A_i \\rbrace$, denoted $\\cup_i A_i = A_1 \\cup A_2 \\cup \\cdots$, is the event that $A_i$ occurs for at least one value of $i$. \\\nThe *intersection* of $\\lbrace{A_i \\rbrace}$, denoted $\\cap_iA_i = A_1 \\cap A_2 \\cap \\cdots$, is the event that $A_i$ occurs for all values of $i$.\n\nIf $A$ and $B$ are two events such that $A \\neq B$, and all the outcomes in $A$ are also in $B$, then $A$ is a *proper subset* of $B$, denoted $A \\subset B$. If $A$ and $B$ are equal, then $A$ is a *subset* of $B$, denoted $A \\subseteq B$. $A \\subset B$ can also be read as \"$A$ implies $B$\". Note that \"subset\" is often said as a shorthand of \"proper subset\" when $A \\subset B$ is used.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/expectation":{"title":"Expectation","content":"\n## Definition\nLet $X$ be a [discrete random variable](statistics/random-variable.md) with [probability mass function](statistics/probability-mass-function.md) $f_X(x)$ where $x \\in S$. Then the expected value of $X$, denoted by $\\mathbb{E}(X)$ and commonly shortened to $\\mathbb{E}X$, is given by\n$$\\mathbb{E}(X) = \\sum_{x \\in S} xf_X(x) = \\sum_{x \\in S} x\\mathbb{P}(X = x).$$\n\nLet $X$ be a continuous random variable with [probability density function](statistics/probability-density-function.md) $f_X(x)$. Then the expected value of $X$ is given by\n$$\\mathbb{E}(X) = \\int_{-\\infty}^\\infty uf(u)du.$$\n\nThe expected value of $X$ is also commonly denoted by $\\mu_X$.\n\n\u003e [!tip] Tip.\n\u003e \n\u003e Intuitively, the expectation of a random variable $X$ is a weighted average of the values that $X$ takes ($x$ in the range of $X$), where the weight is given by the probability of each value in the discrete case, and the density function $f_X$ in the continuous case.\n\n## Properties\nLet $X$ and $Y$ be two arbitrary random variables. Then\n1. $\\mathbb{E}(aX + b) = a\\mathbb{E}X + b$ for all $a, b$\n2. $\\mathbb{E}(X + Y) = \\mathbb{E}X + \\mathbb{E}Y$\n3. $X \\geq Y \\implies \\mathbb{E}X \\geq \\mathbb{E}Y$\n\n**Proof.** The first property follows from applying [LOTUS](statistics/law-of-the-unconscious-statistician.md). For the second property, first define $X: \\Omega \\to \\mathbb{R}$, $Y: \\Omega \\to \\mathbb{R}$ and $Z(\\omega) = X(\\omega) + Y(\\omega)$. Then\n$$\\begin{align*}\n\\mathbb{E}Z \u0026= \\sum_{\\omega\\in\\Omega} Z(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\sum_{\\omega\\in\\Omega} (X(\\omega) + Y(\\omega)) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\sum_{\\omega\\in\\Omega} X(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) + \\sum_{\\omega\\in\\Omega} Y(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\mathbb{E}X + \\mathbb{E}Y,\n\\end{align*}$$\nwith the continuous case following analogously with integrals. For the third property, $X \\geq Y \\implies X - Y \\geq 0 \\implies \\mathbb{E}(X - Y) \\geq 0 \\implies \\mathbb{E}X \\geq \\mathbb{E}Y$, where we use the second property in the last step.","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/exponential-distribution":{"title":"Exponential Distribution","content":"\n## Definition\nThe *exponential distribution* is the continuous probability distribution of the time between events that follow a [Poisson process](statistics/poisson-distribution.md); that is, events occur independently of each other at a constant mean rate of occurrences.\n\nThe exponential distribution is a special case of the [gamma distribution](statistics/gamma-distribution.md).\n\n## Properties\n### Probability Density Function\nLet $X$ be an exponential [random variable](statistics/random-variable.md) with parameter $\\lambda \u003e 0$; that is, $X \\sim \\text{Exp}(\\lambda)$. Then $X$ has [pdf](statistics/probability-density-function.md)\n$$f_X(x) = \\begin{cases}\n0, \u0026 \\text{if } x \u003c 0 \\\\\n\\lambda e^{-\\lambda x}, \u0026 \\text{if } x \\geq 0\n\\end{cases}$$\nand [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = \\begin{cases}\n0, \u0026 \\text{if } x \u003c 0 \\\\\n1 - e^{-\\lambda x}, \u0026 \\text{if } x \\geq 0.\n\\end{cases}$$\n\n## Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = \\lambda \\int_0^\\infty xe^{-\\lambda x}\\thinspace dx = \\int_0^\\infty e^{-\\lambda x} = \\frac{1}{\\lambda},$$\nwhere we can use integration by parts to solve the integral.\n\n### Variance\nWe have\n$$\\mathbb{E}(X^2) = \\int_0^\\infty x^2 \\lambda e^{-\\lambda x} = \\int_0^\\infty 2xe^{-\\lambda x} = \\frac{2}{\\lambda}\\mathbb{E}X = \\frac{2}{\\lambda^2},$$\nso the [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = \\mathbb{E}(X^2) - (\\mathbb{E}X)^2 = \\frac{2}{\\lambda^2} - \\left(\\frac{1}{\\lambda}\\right)^2 = \\frac{1}{\\lambda^2}.$$\n\n### Memoryless Property\nThe exponential distribution has the memoryless property. That is, the probability distribution of the waiting time for an event to occur, given we have waited for some initial time period, is independent of this initial time period.\n\nFor example, if an event is yet to occur after 5 minutes, the probability of requiring 1 more minute is equal to the probability of requiring 1 minute (without having waited the initial 5 minutes). In other words, there is no \"memory\" of the initial time period.\n\nMathematically, this is described as\n$$\\mathbb{P}(X \u003e t + s | X \u003e s) = \\mathbb{P}(X \u003e t).$$\nThis can be seen by evaluating the conditional probability on the left:\n$$\\begin{align*}\n\\mathbb{P}(X \u003e t + s | X \u003e s) \u0026= \\frac{\\mathbb{P}(\\lbrace X \u003e t + s \\rbrace \\cap \\lbrace X \u003e s\\rbrace)}{\\mathbb{P}(X \u003e s)} \\\\\n\u0026= \\frac{\\mathbb{P}(X \u003e t + s)}{\\mathbb{P}(X \u003e s)} \\\\\n\u0026= \\frac{e^{-\\lambda(t + s)}}{e^{-\\lambda s}} \\\\\n\u0026= e^{-\\lambda t} \\\\\n\u0026= \\mathbb{P}(X \u003e t).\n\\end{align*}$$\n\n\u003e [!info] Aside.\n\u003e \n\u003e The only *continuous* probability distribution with the memoryless property is the exponential distribution. The only *discrete* probability distribution with the memoryless property is the [geometric distribution](statistics/geometric-distribution.md).\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/gamma-distribution":{"title":"Gamma Distribution","content":"\n## Definition\nThe *gamma distribution* is a family of continuous probability distributions with 2 parameters; a shape parameter $\\alpha$, and a rate parameter $\\beta$. \n\nThe [exponential distribution](statistics/exponential-distribution.md) is a special case of the gamma distribution. An $\\text{Exp}(\\lambda)$ distribution is precisely the $\\text{Gamma}(1, \\lambda)$ distribution.\n\n\u003e [!info] Aside.\n\u003e \n\u003e Another common parametrization for the distribution uses the same shape parameter $\\alpha$ and a scale parameter $\\theta = 1/\\beta$.\n\n## Properties\n### Probability Density Function\nLet $X$ be a gamma [random variable](statistics/random-variable.md) with shape parameter $\\alpha$ and rate parameter $\\beta$; that is, $X \\sim \\text{Gamma}(\\alpha, \\beta)$. Then $X$ has [pdf](statistics/probability-density-function.md)\n$$f_X(x) = \\frac{x^{\\alpha-1}\\beta^\\alpha e^{-\\beta x}}{\\Gamma(\\alpha)},$$\nwhere $\\Gamma(\\alpha)$ is the [gamma function](mathematics/gamma-function.md).\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by $\\mathbb{E}X = \\alpha/\\beta$.\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by $\\text{Var}(X) = \\alpha/\\beta^2$.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/geometric-distribution":{"title":"Geometric Distribution","content":"\n## Definition\nThe *geometric distribution* with parameter $p$ (success probability) is the discrete probability distribution of the number of [Bernoulli trials](statistics/bernoulli-distribution.md) needed before a success is achieved, taking on the positive integers ($1, 2, 3, \\dots$). Alternatively, it may also be the probability distribution of the number of failures before a success is achieved, taking on the non-negative integers ($0, 1, 2, \\dots$).\n\n\u003e [!warning] Note.\n\u003e \n\u003e The two probability distributions described above are *not* the same (note the difference in supports). Here we will take the first distribution described as convention.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a geometric [random variable](statistics/random-variable.md) with parameter $p$ where $0 \u003c p \u003c 1$; that is, $X \\sim \\text{Geo}(p)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = p(1 - p)^{x-1}$$\nfor a positive integer $x$ (number of trials needed before success), and $0$ otherwise. Also, $X$ has [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = 1 - (1 - p)^{\\lfloor x \\rfloor}$$\nfor $x \\geq 1$, and $0$ otherwise.\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = \\frac{1}{p}.$$\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = \\frac{1 - p}{p^2}.$$\n\n### Memoryless Property\nThe geometric distribution has the memoryless property. That is, the probability distribution of observing the next (or the first) success, given we have already observed some number of failures, is independent of the number of failures observed.\n\nFor example, if we have already observed 20 failures, the probability of requiring 5 more failures is equal to the probability of requiring 5 failures (without having observed the initial 20 failures). In other words, there is no \"memory\" of the additional failures.\n\nMathematically, this is described as\n$$\\mathbb{P}(X \u003e m + n | X \u003e n) = \\mathbb{P}(X \u003e m).$$\nThis can be seen by evaluating the conditional probability on the left:\n$$\\begin{align*}\n\\mathbb{P}(X \u003e m + n | X \u003e n) \u0026= \\frac{\\mathbb{P}(\\lbrace X \u003e m + n \\rbrace \\cap \\lbrace X \u003e n\\rbrace)}{\\mathbb{P}(X \u003e n)} \\\\\n\u0026= \\frac{\\mathbb{P}(X \u003e m + n)}{\\mathbb{P}(X \u003e n)} \\\\\n\u0026= \\frac{(1 - p)^{m+n}}{(1 - p)^n} \\\\\n\u0026= (1 - p)^m \\\\\n\u0026= \\mathbb{P}(X \u003e m).\n\\end{align*}$$\n\n\n\u003e [!info] Aside.\n\u003e \n\u003e The only *discrete* probability distribution with the memoryless property is the geometric distribution. The only *continuous* probability distribution with the memoryless property is the [exponential distribution](statistics/exponential-distribution.md).\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/hypergeometric-distribution":{"title":"Hypergeometric Distribution","content":"\n## Definition\nThe *hypergeometric distribution* with parameters $N$, $n$, and $r$ is the discrete probability distribution of the number of successes (where a success is defined as drawing an object with some certain feature) in $n$ repetitions of drawing without replacement from some population of size $N$ where $r$ objects have the desired feature.\n\nA similar distribution is the [binomial distribution](statistics/binomial-distribution.md), which describes the probability distribution of the number of successes in $n$ repetitions of drawing *with* replacement.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a hypergeometric [random variable](statistics/random-variable.md) with parameters $N, n$, and $r$; that is, $X \\sim \\text{Hyp}(n, r, N)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\frac{\\binom{r}{x} \\binom{N - r}{n - x}}{\\binom{N}{n}},$$\nfor $\\max \\lbrace 0, r + n - N \\rbrace \\leq x \\leq \\min \\lbrace n, r \\rbrace$, and $0$ otherwise.\n\n\u003e [!tip] Tip.\n\u003e \n\u003e To reason about the form of this pmf, consider that there are $\\binom{N}{n}$ total possible outcomes, each of which are equally likely. For each number $x$ of successes, there are $\\binom{r}{x}$ ways of choosing $x$ objects (with the desired feature) from $r$ and $\\binom{N-r}{n-x}$ ways of choosing $n - x$ objects (without the desired feature) from $N - r$.\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = n \\frac{r}{N}.$$\nCompare this with the expectation of a $\\text{Bin}(n, p)$ random variable, $np$.\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = n\\frac{r}{N}\\left(1 - \\frac{r}{N}\\right)\\frac{N - n}{N - 1}.$$\nCompare this with the variance of a $\\text{Bin}(n, p)$ random variable, $np(1 - p)$.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/independence-event":{"title":"Independence (Event)","content":"\n## Definition\nTwo [events](statistics/event.md) $A$ and $B$ are said to be *independent* if $\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)$.\n\nA collection of events $A_1, A_2, \\dots$ is said to be *pairwise independent* if, for all $i \\neq j$, $A_i$ and $A_j$ are independent; that is, $\\mathbb{P}(A_i \\cap A_j) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)$. \\\nThey are said to be *triplewise independent* if, for all distinct $i, j, k$, we have $\\mathbb{P}(A_i \\cap A_j \\cap A_k) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)\\mathbb{P}(A_k)$.\n\nGenerally, they are said to be *mutually independent* if each event is independent of any combination of other events in the collection; that is, $$\\mathbb{P}\\left(\\bigcap_i A_i \\right) = \\prod_i \\mathbb{P}(A_i).$$\n\n## Properties\n\nIf $A$ and $B$ are independent events, then $A^c$ and $B^c$ are independent, i.e. $\\mathbb{P}(A^c \\cap B^c) = \\mathbb{P}(A^c)\\mathbb{P}(B^c)$. \\\n**Proof.** Using [De Morgan's Law](statistics/de-morgans-laws.md), we have $\\mathbb{P}(A^c \\cap B^c) = \\mathbb{P}((A \\cup B)^c)$. Then\n$$\\begin{align*}\n\\mathbb{P}(A^c \\cap B^c) \u0026= 1 - \\mathbb{P}(A \\cup B) \\\\\n\u0026= 1 - [\\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)] \\\\\n\u0026= 1 - [\\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A)\\mathbb{P}(B)] \u0026\u0026 A, B \\text{ independent} \\\\\n\u0026= 1 - \\mathbb{P}(A) - \\mathbb{P}(B) + \\mathbb{P}(A)\\mathbb{P}(B) \\\\\n\u0026= (1 - \\mathbb{P}(A))(1 - \\mathbb{P}(B)) \\\\\n\u0026= \\mathbb{P}(A^c)\\mathbb{P}(B^c).\n\\end{align*}$$\n\n## See Also\n- [Independence (Random Variable)](statistics/independence-(random-variable).md)\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/independence-random-variable":{"title":"Independence (Random Variable)","content":"\n## Definition\nTwo [random variables](statistics/random-variable.md) $X$ and $Y$ are said to be *independent* if and only if the product of their marginal [cdfs](statistics/cumulative-distribution-function.md) is equal to their [joint cdf](statistics/joint-cumulative-distribution-function.md). That is, $F_{X, Y} = F_XF_Y$, or\n$$\\mathbb{P}(X \\leq x, Y \\leq y) = \\mathbb{P}(X \\leq x)\\mathbb{P}(Y \\leq y)$$\nfor all $x, y \\in \\mathbb{R}$.\n\nEquivalently, $X$ and $Y$ are independent if and only if the product of their marginal [pdfs](statistics/probability-density-function.md) is equal to their joint pdf *\\[link needed\\]*. That is, $f_{X, Y} = f_X f_Y$.\n\n## See Also\n- [Independence (Event)](statistics/independence-(event).md)\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/inverse-transform-method":{"title":"Inverse Transform Method","content":"\n## Definition\nThe *inverse-transform method* is a method of generating (one-dimensional) [random variables](statistics/random-variable.md) from a given distribution with [cdf](statistics/cumulative-distribution-function.md) $F$, which has inverse $F^{-1}$.\n\n## Method\n### Continuous Distribution\nSince $U \\sim \\mathcal{U}[0, 1]$, the random variable $X = F^{-1}(U)$ has cdf $F$; that is,\n$$\\mathbb{P}(X \\leq x) = \\mathbb{P}(F^{-1}(U) \\leq x) = \\mathbb{P}(U \\leq F(x)) = F(x).$$\n\nThus the method is as follows:\n1. Generate $U \\sim \\mathcal{U}[0, 1]$ (see [uniform distribution](statistics/uniform-distribution.md)).\n2. Return $X = F^{-1}(U)$.\n\n### Discrete Distribution\nThe inverse-transform method can also be used to simulate a discrete random variable $X$ with $\\mathbb{P}(X = x_i) = p_i$ for $i \\in \\mathbb{N}$.\n\n1. Generate $U \\sim \\mathcal{U}[0, 1]$.\n2. Find the smallest positive integer $k$ such that $U \\leq F(X_k)$ and return $X = x_k$.\n\n## See Also\n- [Acceptance Rejection Method](statistics/acceptance-rejection-method.md)\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/joint-cumulative-distribution-function":{"title":"Joint Cumulative Distribution Function","content":"\n## Definition\nLet $X$ and $Y$ be two [random variables](statistics/random-variable.md). Then the function\n$$F_{X, Y}(x, y) = \\mathbb{P}(X \\leq x, Y \\leq y)$$\nis the *joint cumulative distribution function* of $X$ and $Y$.\n\nWe have\n$$\\mathbb{P}(X \\leq x) = F_X(x) = \\lim_{y\\to\\infty} F_{X, Y}(x, y)$$\nand\n$$\\mathbb{P}(Y \\leq y) = F_Y(y) = \\lim_{x\\to\\infty} F_{X, Y}(x, y).$$\n\n$F_X$ and $F_Y$ are referred to as *marginal* cumulative distribution functions.\n\n## See Also\n- [Cumulative Distribution Function](statistics/cumulative-distribution-function.md)\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/joint-probability-mass-function":{"title":"Joint Probability Mass Function","content":"\n## Definition\nLet $X$ and $Y$ be two [discrete random variables](statistics/random-variable.md). Then the function\n$$f(x, y) = \\mathbb{P}(X = x, Y = y), \\quad x, y \\in \\mathbb{R}$$\nis the *joint probability (mass) function* of $X$ and $Y$. It is often denoted $f_{X, Y}(x, y)$.\n\nIf $S_X = \\lbrace x_1, x_2, \\dots \\rbrace$ is the range of $X$ and $S_Y = \\lbrace y_1, y_2, \\dots \\rbrace$ is the range of $Y$, then $S_{X, Y} = S_X \\times S_Y$ is the range of $(X, Y)$, where $\\times$ is the cross product operator, i.e. $S_{X, Y} = \\lbrace (x, y) | x \\in S_X, y \\in S_Y \\rbrace$.\n\n## Properties\nLet $X$, $Y$, and $f_{X, Y}$ be defined as above, and let $f_X$ be the marginal [pmf](statistics/probability-mass-function.md) of $X$, and $f_Y$ the marginal pmf of $Y$. Then the following properties hold:\n- $f_X(x) = \\sum_y f_{X, Y}(x, y)$ and $f_Y(y) = \\sum_y f_{X, Y}(x, y)$\n- $f_{X, Y}(x, y) \u003e 0$ only if $(x, y) \\in S_{X, Y}$\n- $\\sum_x \\sum_y f_{X, Y}(x_i, y_j) = 1$\n- $F_{X, Y}(x, y) = \\sum_{u \\leq x} \\sum_{v \\leq y} f_{X, Y}(u, v)$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/law-of-the-unconscious-statistician":{"title":"Law of the Unconscious Statistician","content":"\n## Definition\nLet $X$ be a [discrete random variable](statistics/random-variable.md) with support $S$ and with [probability mass function](statistics/probability-mass-function.md) $f_X(x)$ where $x \\in S$, and let $g(X)$ be some function of $X$. Then the [expectation](statistics/expectation.md) of $g(X)$ is given by\n$$\\mathbb{E}(g(X)) = \\sum_{x \\in S} g(x)f_X(x) = \\sum_{x \\in S} g(x) \\mathbb{P}(X = x).$$\n\nIf $X: \\Omega \\to \\mathbb{R}$ is a continuous random variable with [probability density function](statistics/probability-density-function.md) $f_X(x)$ where $x \\in \\Omega$, and let $g(X)$ be some function of $X$. Then the expectation of $g(X)$ is given by\n$$\\mathbb{E}(g(X)) = \\int_{-\\infty}^\\infty g(x)f_X(x) \\thinspace dx$$\n\nThe Law of the Unconscious Statistician is often shortened to LOTUS.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/law-of-total-probability":{"title":"Law of Total Probability","content":"\n## Definition\nIf $A$ and $B$ are [events](statistics/event.md) such that $0 \u003c \\mathbb{P}(B) \u003c 1$, then\n$$\\mathbb{P}(A) = \\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c).$$\nMore generally, if $\\lbrace B_i \\rbrace$ is a collection of events that form a [partition](statistics/partition.md) of $\\Omega$ such that $\\mathbb{P}(B_i) \u003e 0$ for at least one $i$,  then\n$$\\mathbb{P}(A) = \\sum_i \\mathbb{P}(A|B_i)\\mathbb{P}(B_i) = \\sum_i \\mathbb{P}(A \\cap B_i)$$\nfor any event $A$, by the definition of [conditional probability](statistics/conditional-probability.md).\n\n## Proof\nWe have\n$$A = A \\cap \\Omega = A \\cap (B \\cup B^c) = (A \\cap B) \\cup (A \\cap B^c),$$\nwhere $A \\cap B$ and $A \\cap B^c$ are disjoint events. Then from the [third axiom of probability](statistics/probability-measure.md) and the definition of conditional probability,\n$$\\mathbb{P}(A) = \\mathbb{P}(A \\cap B) + \\mathbb{P}(A \\cap B^c) = \\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c).$$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/markovs-inequality":{"title":"Markov's Inequality","content":"\n## Definition\nLet $X$ be a non-negative [random variable](statistics/random-variable.md) (i.e. $X \\geq 0$) and $a \\in \\mathbb{R}$ a non-negative number. Then\n$$\\mathbb{P}(X \\geq a) \\leq \\frac{\\mathbb{E}(X)}{a}.$$\n\n## Proof\nDefine $A = \\lbrace \\omega \\in \\Omega : X(\\omega) \\geq a \\rbrace$. Then the random variable $X - a \\cdot \\mathbb{I}_A \\geq 0$, since if the outcome is in $A$, $X \\geq a$ and $a - a \\cdot \\mathbb{I}_A = 0$ implies $X \\geq a \\cdot \\mathbb{I}_A$, and if the outcome is not in $A$, $\\mathbb{I}_A = 0$ which implies $X - a \\cdot \\mathbb{I}_A = X \\geq 0$. Taking the [expectation](statistics/expectation.md) of this random variable yields\n$$\\begin{align*}\n\\mathbb{E}(X - a \\cdot \\mathbb{I}_A) \u0026\\geq 0 \\\\\n\\mathbb{E}X - a \\cdot \\mathbb{E}(\\mathbb{I}_A) \u0026\\geq 0 \\\\\n\\mathbb{E}X - a \\cdot \\mathbb{P}(A) \u0026\\geq 0 \\\\\na \\cdot \\mathbb{P}(A) \u0026\\leq \\mathbb{E}X \\\\\n\\therefore \\mathbb{P}(A) \\leq \\frac{\\mathbb{E}X}{a}.\n\\end{align*}$$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/moment":{"title":"Moment","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the n-th *moment* of $X$ is given by $\\mathbb{E}(X^n)$.\n\nFor example, the [expectation](statistics/expectation.md) of $X$ is the first moment of $X$, and the [variance](statistics/variance.md) of $X$ is the second moment of $X$ minus the square of the first moment of $X$.\n\n\u003e [!info] Aside.\n\u003e \n\u003e There are also other types of moments. For an arbitrary random variable $X$,\n\u003e - $\\mathbb{E}((X - \\mu_X)^n)$ is called the n-th *central moment* of $X$. For example, the variance of $X$ is the second central moment of $X$.\n\u003e - $\\mathbb{E}(((X - \\mu_X)/\\sigma_X)^n)$ is called the n-th *standardized moment* of $X$. For example, the third standardized moment of $X$ is called the *skewness* of $X$.\n\u003e - $\\mathbb{E}(X(X - 1)\\cdots(X - (n - 1)))$ is called the n-th *factorial moment* of $X$.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/moment-generating-function":{"title":"Moment Generating Function","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the *moment generating function* (MGF) of $X$ is defined as\n$$M(t) = \\mathbb{E}(e^{tX}), \\quad t \\in \\mathbb{R}$$\nprovided the expectation exists on some open interval $I$ containing 0, where we often write $M_X(z)$ to emphasize the role of $X$ (especially with dealing with multiple MGFs).\n\nIf $X$ is a discrete random variable with range $S$,\n$$M_X(t) = \\sum_{x \\in S} e^{tx}f_X(x), \\quad t \\in I$$\nand if $X$ is a continuous random variable,\n$$M_X(t) = \\int_{-\\infty}^\\infty e^{tx} f_X(x) \\thinspace dx, \\quad t \\in I.$$\n\n\u003e [!warning] Note.\n\u003e \n\u003e If $X$ is a non-negative discrete random variable (that is, it takes values in the non-negative integers), then $M_X(t) = G_X(e^t)$ for $t \\in I$, where $G_X$ is the [PGF](statistics/probability-generating-function.md) of $X$, in which case we would usually use PGFs over MGFs.\n\n## Properties\nLet $X$ be an arbitrary random variable with MGF $M(t)$. Then $M$ has the following properties:\n1. $M$ determines the distribution of $X$ uniquely; two MGFs are the same if and only if their [cumulative distribution functions](statistics/cumulative-distribution-function.md) are the same.\n2. The [expectation](statistics/expectation.md) of $X$ is given by $\\mathbb{E}X = M'(0)$.\n3. More generally, $\\mathbb{E}(X^n) = M^{(n)}(0), n \\geq 1$, i.e. $M^{(n)}(0)$ gives the n-th [moment](statistics/moment.md) of $X$.\n4. From 2 and 3, we have that the [variance](statistics/variance.md) of $X$ is given by $\\text{Var}(X) = M''(0) - (M'(0))^2$.","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/normal-distribution":{"title":"Normal Distribution","content":"\n## Definition\nThe *normal distribution* is a family of continuous probability distributions with parameters $\\mu$ and $\\sigma$. The parameter $\\mu$ is the expectation (as well as the median and mode), and the parameter $\\sigma$ is the standard deviation. The variance is given by $\\sigma^2$.\n\nThe normal distribution is often referred to as a *bell curve* distribution.\n\n## Properties\n### Probability Density Function\nLet $X$ be a normal [random variable](statistics/random-variable.md) with parameters $\\mu$ and $\\sigma^2$; that is, $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$. Then $X$ has [pdf](statistics/probability-density-function.md)\n$$f_X(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\text{exp}\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$$\nfor $x \\in \\mathbb{R}$. If $X \\sim \\mathcal{N}(0, 1)$, then $X$ is said to have a *standard* normal distribution with pdf\n$$f_X(x) = \\frac{1}{\\sqrt{2\\pi}} \\text{exp}\\left(-\\frac{x^2}{2}\\right).$$\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by $\\mathbb{E}X = \\mu$.\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by $\\text{Var}(X) = \\sigma^2$.\n\n### Standardization\nLet $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and define $Z := (X - \\mu)/\\sigma$. Then\n$$\\mathbb{E}Z = \\mathbb{E}X/\\sigma - \\mu/\\sigma = 0$$\nand\n$$\\text{Var}(Z) = \\text{Var}(X)/\\sigma^2 = 1,$$\nand it can be shown that $Z \\sim \\mathcal{N}(0, 1)$.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/partition":{"title":"Partition","content":"\n## Definition\n[Events](statistics/event.md) $A_1, A_2, \\dots$ are said to be *exhaustive* if $A_1 \\cup A_2 \\cup \\cdots = \\Omega$, that is at least one $A_i$ must occur.\n\nIf $A_1, A_2, \\dots$ are exhaustive and mutually exclusive (i.e. they cannot occur simultaneously), then they are a *partition* of $\\Omega$ and are said to partition the sample space.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/poisson-distribution":{"title":"Poisson Distribution","content":"\n## Definition\nThe *Poisson distribution* with parameter $\\lambda \u003e 0$ (mean rate) is the discrete probability distribution of the number of events occurring in a fixed time interval where events occur independently of each other at a constant mean rate of occurrences.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a Poisson [random variable](statistics/random-variable.md) with parameter $\\lambda \u003e 0$; that is, $X \\sim \\text{Poi}(\\lambda)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}$$\nfor a non-negative integer $x$ (number of occurrences), and $0$ otherwise.\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = \\lambda.$$\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = \\lambda.$$\n\n### Connection to binomial distribution\nThe Poisson $\\text{Poi}(np)$ distribution is the limiting distribution of a [binomial](statistics/binomial-distribution.md) $\\text{Bin}(n, p)$ distribution. To see this, suppose $X \\sim \\text{Bin}(n, p)$ and let $\\lambda = np \u003e 0$. Now let the number of trials $n$ tend to infinity, whilst holding the product $np$ constant. The expectation of $X$ is given by\n$$\\mathbb{E}X = np = \\lambda,$$\nand the variance of $X$ is given by\n$$\\text{Var}(X) = np(1 - p) = n \\left(\\frac{\\lambda}{n}\\right) \\left(1 - \\frac{\\lambda}{n}\\right) = \\lambda \\left(1 - \\frac{\\lambda}{n}\\right),$$\nwhich tends to $\\lambda$ as $n \\to \\infty$. The pmf of $X$, for support $x \\in 0, 1, 2, \\dots$, is given by\n$$\\begin{align*}\n\\mathbb{P}(X = x) \u0026= \\binom{n}{x} \\left(\\frac{\\lambda}{n}\\right)^x \\left(1 - \\frac{\\lambda}{n}\\right)^{n-x} \\\\\n\u0026= \\frac{n \\times (n - 1) \\times \\cdots \\times (n - x + 1)}{x!} \\frac{\\lambda^x}{n^x} \\left(1 - \\frac{\\lambda}{n}\\right)^n \\left(1 - \\frac{\\lambda}{n}\\right)^{-x},\n\\end{align*}$$\nwhere we can take the limits of each component separately:\n$$\\lim_{n\\to\\infty} \\left(\\frac{n \\times (n - 1) \\times \\cdots \\times (n - x + 1)}{x!} \\frac{\\lambda^x}{n^x}\\right) = \\frac{\\lambda^x}{x!}$$\n$$\\lim_{n\\to\\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^n = e^{-\\lambda}$$\n$$\\lim_{n\\to\\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{-x} = 1,$$\nyielding\n$$\\mathbb{P}(X = x) \\to \\frac{\\lambda^x e^{-\\lambda}}{x!},$$\nwhich is precisely the pmf of a Poisson random variable.\n\nIt follows that the Poisson $\\text{Poi}(np)$ distribution approximates the binomial $\\text{Bin}(n, p)$ distribution when $n$ is sufficiently large and $p$ is sufficiently small. A good rule of thumb is to have $n \\geq 20$ and $p \\leq 0.05$.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/probability-density-function":{"title":"Probability Density Function","content":"\n## Definition\nIf $X: \\Omega \\to \\mathbb{R}$ is a *[continuous random variable](statistics/random-variable.md)*, then the function $f$ such that $f(x) \\geq 0$ for all $x \\in \\Omega$ and\n$$\\mathbb{P}(x \\leq X \\leq y) = \\int_x^y f(u)du$$\nfor all $x \\leq y$, that is, the probability that $X$ takes on values in the interval $[x, y]$ is given by the area under the graph of the pdf from $x$ to $y$. It is often denoted $f_X(x).$\n\n\u003e [!warning] Note.\n\u003e \n\u003e Note that $f(x)$ is *not* a probability; it should be thought of as a *probability density*. It is not true that $f(x) = \\mathbb{P}(X = x)$ for all $x$. In fact, we have $\\mathbb{P}(X = x) = 0$ for all $x$ in the support of $X$.\n\n## Properties\nIf $X$ is a continuous random variable taking values in $\\Omega$, then\n1. $f_X(x) \\geq 0$ for all real $x$\n2. $\\int_{-\\infty}^\\infty f_X(u) du = 1$\n3. $F_X(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(u) du$, where $F_X(x)$ is the [cumulative distribution function](statistics/cumulative-distribution-function.md). Additionally, if $f_X(x)$ exists, $F'_X(x) = f_X(x)$.\n\n## See Also\n- [Probability Mass Function](statistics/probability-mass-function.md)\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/probability-generating-function":{"title":"Probability Generating Function","content":"\n## Definition\nLet $X$ be a non-negative [discrete random variable](statistics/random-variable.md). Then the *probability generating function* (PGF) of $X$ is defined as\n$$G(z) = \\mathbb{E}(z^X) = \\sum_{k=0}^\\infty z^k \\mathbb{P}(X = k), \\quad |z| \\leq 1,$$\nwhere we often write $G_X(z)$ to emphasize the role of $X$ (especially when dealing with multiple PGFs).\n\nMathematically, $G$ is a *power series* *\\[link needed\\]* with coefficients $a_k = \\mathbb{P}(X = k)$, and converges *\\[link needed\\]* for all $|z| \\leq 1$ and often for $|z| \\leq R$ where $R \u003e 1$. As such, it can be differentiated or integrated term-wise.\n\n## Properties\nLet $X$ be a non-negative discrete random variable with PGF $G(z)$. Then $G$ has the following properties:\n1. $G$ determines the distribution of $X$ uniquely with\n   $$\\mathbb{P}(X = k) = \\frac{G^{(k)}(0)}{k!}, \\quad k \\geq 1.$$\n2. The [expectation](statistics/expectation.md) of $X$ is given by $\\mathbb{E}X = G'(1)$.\n3. More generally, $\\mathbb{E}(X(X - 1)\\cdot(X - (k - 1))) = G^{(k)}(1), k \\geq 1$, i.e. $G^{(k)}(1)$ gives the k-th [factorial moment](statistics/moment.md) of $X$.\n4. From 2 and 3, we have that the [variance](statistics/variance.md) of $X$ is given by $\\text{Var}(X) = G''(1) + G'(1) - (G'(1))^2$.\n\n\u003e [!warning] Note.\n\u003e \n\u003e $G'(1)$ (and $G^{(k)}(1)$ etc.) may not be defined if $R = 1$, in which case we conventionally take $G(1)$ to be the limit from below, i.e. $G(1) = \\lim_{z\\to1^-} G(z)$.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/probability-mass-function":{"title":"Probability Mass Function","content":"\n## Definition\nIf $X$ is a *[discrete random variable](statistics/random-variable.md)*, then the function\n$$f(x) = \\mathbb{P}(X = x), \\quad x \\in \\mathbb{R}$$\nis the *probability (mass) function* of $X$. It is often denoted $f_X(x)$.\n\n## Properties\nIf $X$ is a discrete random variable taking values in $S$, then\n1. $f_X(x) \\geq 0$ for all real $x$\n2. $\\sum_{x\\in S} f_X(x) = 1$.\n3. $F_X(x) = \\mathbb{P}(X \\leq x) = \\sum_{y \\in S | y \\leq x} f_X(y)$, where $F_X(x)$ is the [cumulative distribution function](statistics/cumulative-distribution-function.md).\n\n## See Also\n- [Probability Density Function](statistics/probability-density-function.md)\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/probability-measure":{"title":"Probability Measure","content":"\n## Definition\nThe function $\\mathbb{P}$ is called a *probability measure* if it satisfies the following properties, or *axioms*:\n1. $\\mathbb{P}(A) \\geq 0$ for all events $A$\n2. $\\mathbb{P}(\\Omega) = 1$\n3. If $A_1, A_2, \\dots$ are [mutually exclusive events](statistics/event.md), then $\\mathbb{P}(A_1 \\cup A_2 \\cup \\cdots) = \\mathbb{P}(A_1) + \\mathbb{P}(A_2) + \\cdots$\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/random-variable":{"title":"Random Variable","content":"\n## Definition\nA random variable $X$ is a function or mapping from the possible outcomes in a [sample space](statistics/sample-space.md) to numerical values, usually the real numbers.\n\nA random variable is said to be *discrete* if it takes values in (i.e. maps to) a countable set.\n\nA random variable is said to be *continuous* if it takes values in (i.e. maps to) an *interval*.\n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/sample-space":{"title":"Sample Space","content":"\n## Definition\nThe set $\\Omega$ of all possible outcomes of an experiment or random trial is called the *sample space*. \n","lastmodified":"2023-02-21T14:36:12.020319386Z","tags":null},"/statistics/uniform-distribution":{"title":"Uniform Distribution","content":"\n## Definition\nThe *uniform distribution* is the continuous probability distribution that takes on values in the support $[a, b]$ (or $(a, b)$ for an open interval) such that all intervals (contained in the support) of the same length have equal probability. A random variable $X$ that is uniformly distributed on $[a, b]$ satisfies\n$$\\mathbb{P}(x \\leq X \\leq y) = \\frac{y - x}{b - a}, a \\leq x \\leq y \\leq b,$$\nthat is the probability of taking on a value in a particular interval is directly proportional to the interval's length.\n\n## Properties\n### Probability Density Function\nLet $X$ be a uniform [random variable](statistics/random-variable.md) on $[a, b]$; that is, $X \\sim \\mathcal{U}[a, b]$. Then $X$ has [pdf](statistics/probability-density-function.md)\n$$f_X(x) = \\begin{cases}\n\\frac{1}{b-a}, \u0026 \\text{if } a \\leq x \\leq b \\\\\n0, \u0026 \\text{otherwise.}\n\\end{cases}$$\nand [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = \\begin{cases}\n0, \u0026 \\text{if } x \u003c a \\\\\n\\frac{x - a}{b - a}, \u0026 \\text{if } a \\leq x \\leq b \\\\\n1, \u0026 \\text{if } x \u003e b.\n\\end{cases}$$\n\n## Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = \\frac{1}{b-a} \\int_a^b x \\thinspace dx = \\frac{b^2 - a^2}{2(b - a)} = \\frac{a + b}{2},$$\nwhich intuitively makes sense as it is the mean of the bounds $a$ and $b$.\n\n## Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\begin{align*}\n\\text{Var}(X) \u0026= \\mathbb{E}(X^2) - (\\mathbb{E}X)^2 \\\\\n\u0026= \\frac{1}{b - a}\\int_a^b x^2 \\thinspace dx - \\left(\\frac{a + b}{2}\\right)^2 \\\\\n\u0026= \\frac{a^2 + ab + b^2}{3} - \\frac{a^2 + 2ab + b^2}{4} \\\\\n\u0026= \\frac{(b - a)^2}{12},\n\\end{align*}$$\nwhere we use difference of cubes in the third step.\n","lastmodified":"2023-02-21T14:36:12.024319423Z","tags":null},"/statistics/variance":{"title":"Variance","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the *variance* of $X$, denoted $\\text{Var}(X)$, is given by\n$$\\text{Var}(X) = \\mathbb{E}(X - \\mu_X)^2,$$ and quantities the spread of the distribution of $X$, or the variation about the mean, $\\mu_X$.\n\nThe variance may also be written as:\n$$\\text{Var}(X) = \\mathbb{E}(X - \\mu_X)^2 = \\mathbb{E}(X^2) - 2\\mu_x\\mathbb{E}X + \\mu_X^2 = \\mu_X^2 = \\mathbb{E}(X^2) - \\mu_X^2.$$\n\nThe variance of $X$ is also commonly denoted by $\\sigma_X^2$, where $\\sigma_X$ is the *standard deviation* of $X$.\n\n## Properties\nIf $X$ is any arbitrary random variable, then $\\text{Var}(aX + b) = a^2\\text{Var}(X)$ for all $a$ and $b$. \\\n**Proof.** We have\n$$\\begin{align*}\n\\text{Var}(aX + b) \u0026= \\mathbb{E}(aX + b)^2 - (\\mathbb{E}(aX + b))^2 \\\\\n\u0026= \\mathbb{E}(a^2X^2 + 2abX + b^2) - (a\\mathbb{E}X + b)^2 \\\\\n\u0026= \\mathbb{E}(a^2X^2 + 2abX + b^2) - (a^2(\\mathbb{E}X)^2 + 2ab\\mathbb{E}X + b^2) \\\\\n\u0026= a^2(\\mathbb{E}(X^2) - (\\mathbb{E}X)^2) \\\\\n\u0026= a^2\\text{Var}(X)\n\\end{align*}$$\n","lastmodified":"2023-02-21T14:36:12.024319423Z","tags":null}}
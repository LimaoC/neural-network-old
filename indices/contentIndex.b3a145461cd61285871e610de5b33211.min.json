{"/":{"title":"Neural Network","content":"\nHello, and welcome to my neural network! This is where I store my second brain - filled with notes from my mathematics and computer science degrees. My main motivation for maintaining this is ...\n\nIf you spot any mistakes, or have any suggestions, feel free to create an issue over at the [Github repo](https://github.com/LimaoC/neural-network), or click on the \"edit source\" button on any of the pages.\n\nTip: use `ctrl + k` to quick search.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/bayes-theorem":{"title":"Bayes' Theorem","content":"\n## Definition\nLet $A$ and $B$ be arbitrary [events](statistics/event.md) such that $\\mathbb{P}(A) \u003e 0$ and $0 \u003c \\mathbb{P}(B) \u003c 1$. Then\n$$\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)} = \\frac{\\mathbb{P}(A|B)\\mathbb{P}(B)}{\\mathbb{P}(A)},$$\nusing the definition of [conditional probability](statistics/conditional-probability.md) twice and the [Law of Total Probability](statistics/law-of-total-probability.md).\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/bernoulli-distribution":{"title":"Bernoulli Distribution","content":"\n## Definition\nThe *Bernoulli distribution* is the discrete probability distribution with parameter $p$ (success probability) that takes the value 1 with probability $p$ and the value 0 with probability $1 - p$.\n\nThe Bernoulli distribution is a special case of the [binomial distribution](statistics/binomial-distribution.md) with $n = 1$.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a *Bernoulli [random variable](statistics/random-variable.md)* with success probability $p$; that is, $X \\sim \\text{Ber}(p)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\begin{cases}\np, \u0026\u0026 \\text{if } x = 1 \\\\\n1 - p, \u0026\u0026 \\text{if } x = 0 \\\\\n0, \u0026\u0026 \\text{otherwise}.\n\\end{cases}$$\nand [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = \\begin{cases}\n0, \u0026\u0026 \\text{if } x \u003c 0 \\\\\n1 - p, \u0026\u0026 \\text{if } 0 \\leq x \u003c 1 \\\\\n1, \u0026\u0026 \\text{if } x \u003e= 1.\n\\end{cases}$$\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = 0 \\cdot (1 - p) + 1 \\cdot p = p.$$\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\begin{align*}\n\\text{Var}(X) \u0026= \\mathbb{E}(X^2) - (\\mathbb{E}X)^2 \\\\\n\u0026= (0^2 \\cdot (1 - p) + 1^2 \\cdot p) - p^2 \\\\\n\u0026= p - p^2 = p(1 - p).\n\\end{align*}$$\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/binomial-distribution":{"title":"Binomial Distribution","content":"\n## Definition\nThe *binomial distribution* with parameters $n$ (number of trials) and $p$ (success probability) is the discrete probability distribution of the number of successes in $n$ independent experiments, each taking on the value 1 with probability $p$ and the value 0 with probability $1 - p$.\n\nThe [Bernoulli distribution](statistics/bernoulli-distribution.md) is a special case of the binomial distribution with $n = 1$.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a binomial [random variable](statistics/random-variable.md) with $n$ trials and success probability $p$; that is, $X \\sim \\text{Bin}(n, p)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\binom{n}{x} p^x (1 - p)^{n-x}$$\nfor a non-negative integer $x$ (number of successes), and $0$ otherwise. The quantity\n$$\\binom{n}{x} = \\frac{n!}{x!(n-x)!}$$\nis the *binomial coefficient* *\\[link needed\\]*. Note that omitting the binomial coefficient gives us the pmf of a Bernoulli random variable; the binomial coefficient gives us the number of ways in which we can arrange $x$ successes and $n - x$ failures.\n$X$ has [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = \\sum_{k=0}^{\\lfloor k \\rfloor} \\binom{n}{k} p^k (1 - p)^{n-k}.$$\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = np,$$\nwhich follows from applying linearity of expectation to the fact that $X$ is equivalent to the sum of $n$ Bernoulli random variables each with expectation $p$.\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = np(1 - p),$$\nwhich follows from the fact that the variance of the sum of independent random variables is the sum of the variances *\\[link needed\\]*.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/booles-inequality":{"title":"Boole's Inequality","content":"\n## Definition\nFor any [events](statistics/event.md) $A_1, A_2, \\dots$, we have\n$$\\mathbb{P}\\left(\\bigcup_i A_i\\right) \\leq \\sum_i \\mathbb{P}(A_i).$$\nThat is, the probability that at least one of the events occurs is less than or equal to the sum of the probabilities of the individual events.\n\n## Proof\nWe proceed by induction. The $n = 1$ case holds, since $\\mathbb{P}(A_1) \\leq \\mathbb{P}(A_1)$. Then assume the $n = k$ case holds; that is,\n$$\\mathbb{P}\\left(\\bigcup_{i=1}^k A_i\\right) \\leq \\sum_{i=1}^k \\mathbb{P}(A_i).$$\nUsing $\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)$, \n$$\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) = \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) - \\mathbb{P}\\left(\\left(\\bigcup_{i=1}^n A_i \\right) \\bigcap A_{k+1} \\right),$$\nand since $\\mathbb{P}(E) \\geq 0$ for any event $E$ ([first axiom of probability](statistics/probability-measure.md)),\n$$\\begin{align*}\n\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) \u0026\\leq \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026\\leq \\sum_{i=1}^k \\mathbb{P}(A_i) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026= \\sum_{i=1}^{k+1} \\mathbb{P}(A_i).\n\\end{align*}$$\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/conditional-probability":{"title":"Conditional Probability","content":"\n## Definition\nThe [event](statistics/event.md) that $A$ occurs, given that we know $B$ has occurred, is denoted $A | B$. We have\n$$\\mathbb{P}(A | B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)},$$\nwhere $\\mathbb{P}(B \u003e 0)$. \n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/cumulative-distribution-function":{"title":"Cumulative Distribution Function","content":"\n## Definition\nIf $X$ is an arbitrary [random variable](statistics/random-variable.md), then the function\n$$F(x) = \\mathbb{P}(X \\leq x)$$\nis the *(cumulative) distribution function* of $X$. It is often denoted $F_X(x)$.\n\n## Properties\nLet $X$ be a random variable. Then the distribution function $F$ has the following properties:\n1. $F(x) \\to 0$ as $x \\to -\\infty$.\n2. $F(x) \\to 1$ as $x \\to \\infty$.\n3. $F$ is an increasing function; that is $x \u003e y \\implies F(x) \\geq F(y)$.\n4. $F$ is continuous from the right; that is, for all $x$, $F(x + h) \\to F(x)$ as $h \\downarrow 0$ (limit from above).\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/de-morgans-laws":{"title":"De Morgan's Laws","content":"\n## Definition\nLet $\\lbrace A_i \\rbrace$ be a collection of [events](statistics/event.md). Then\n$$\\left(\\bigcup_i A_i\\right)^c = \\bigcap_i A_i^c \\quad\\text{and}\\quad\\left(\\bigcap_i A_i\\right)^c = \\bigcup_i A_i^c.$$\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/disjoint-event":{"title":"Disjoint Event","content":"\n## Definition\nIf $A$ and $B$ are two [events](statistics/event.md) such that they share no outcomes in common, they are said to be *disjoint*, that is $A \\cap B = \\varnothing$. More generally, $A_1, A_2, \\dots$ is said to be *disjoint* if each pair of events $(A_i, A_j$) with $i \\neq j$, is disjoint.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/event":{"title":"Event","content":"\n## Definition\nAn *event* is any subset of outcomes; that is, any subset of the [sample space](statistics/sample-space.md) $\\Omega$.\n\nIf $A$ is an event, then $A$ complement, denoted $A^c$, is the event that $A$ does not occur.\n\nLet $\\lbrace A_i \\rbrace$ be a collection of events. \\\nThe *union* of $\\lbrace A_i \\rbrace$, denoted $\\cup_i A_i = A_1 \\cup A_2 \\cup \\cdots$, is the event that $A_i$ occurs for at least one value of $i$. \\\nThe *intersection* of $\\lbrace{A_i \\rbrace}$, denoted $\\cap_iA_i = A_1 \\cap A_2 \\cap \\cdots$, is the event that $A_i$ occurs for all values of $i$.\n\nIf $A$ and $B$ are two events such that $A \\neq B$, and all the outcomes in $A$ are also in $B$, then $A$ is a *proper subset* of $B$, denoted $A \\subset B$. If $A$ and $B$ are equal, then $A$ is a *subset* of $B$, denoted $A \\subseteq B$. $A \\subset B$ can also be read as \"$A$ implies $B$\". Note that \"subset\" is often said as a shorthand of \"proper subset\" when $A \\subset B$ is used.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/expectation":{"title":"Expectation","content":"\n## Definition\nLet $X$ be a [discrete random variable](statistics/random-variable.md) with [probability mass function](statistics/probability-mass-function.md) $f_X(x)$ where $x \\in S$. Then the expected value of $X$, denoted by $\\mathbb{E}(X)$ and commonly shortened to $\\mathbb{E}X$, is given by\n$$\\mathbb{E}(X) = \\sum_{x \\in S} xf_X(x) = \\sum_{x \\in S} x\\mathbb{P}(X = x).$$\n\nLet $X$ be a continuous random variable with [probability density function](statistics/probability-density-function.md) $f_X(x)$. Then the expected value of $X$ is given by\n$$\\mathbb{E}(X) = \\int_{-\\infty}^\\infty uf(u)du.$$\n\nThe expected value of $X$ is also commonly denoted by $\\mu_X$.\n\n\u003e [!tip] Tip.\n\u003e \n\u003e Intuitively, the expectation of a random variable $X$ is a weighted average of the values that $X$ takes ($x$ in the range of $X$), where the weight is given by the probability of each value in the discrete case, and the density function $f_X$ in the continuous case.\n\n## Properties\nLet $X$ and $Y$ be two arbitrary random variables. Then\n1. $\\mathbb{E}(aX + b) = a\\mathbb{E}X + b$ for all $a, b$\n2. $\\mathbb{E}(X + Y) = \\mathbb{E}X + \\mathbb{E}Y$\n3. $X \\geq Y \\implies \\mathbb{E}X \\geq \\mathbb{E}Y$\n\n**Proof.** The first property follows from applying [LOTUS](statistics/law-of-the-unconscious-statistician.md). For the second property, first define $X: \\Omega \\to \\mathbb{R}$, $Y: \\Omega \\to \\mathbb{R}$ and $Z(\\omega) = X(\\omega) + Y(\\omega)$. Then\n$$\\begin{align*}\n\\mathbb{E}Z \u0026= \\sum_{\\omega\\in\\Omega} Z(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\sum_{\\omega\\in\\Omega} (X(\\omega) + Y(\\omega)) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\sum_{\\omega\\in\\Omega} X(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) + \\sum_{\\omega\\in\\Omega} Y(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\mathbb{E}X + \\mathbb{E}Y,\n\\end{align*}$$\nwith the continuous case following analogously with integrals. For the third property, $X \\geq Y \\implies X - Y \\geq 0 \\implies \\mathbb{E}(X - Y) \\geq 0 \\implies \\mathbb{E}X \\geq \\mathbb{E}Y$, where we use the second property in the last step.","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/geometric-distribution":{"title":"Geometric Distribution","content":"\n## Definition\nThe *geometric distribution* with parameter $p$ (success probability) is the discrete probability distribution of the number of [Bernoulli trials](statistics/bernoulli-distribution.md) needed before a success is achieved, taking on the positive integers ($1, 2, 3, \\dots$). Alternatively, it may also be the probability distribution of the number of failures before a success is achieved, taking on the non-negative integers ($0, 1, 2, \\dots$).\n\n\u003e [!warning] Note.\n\u003e \n\u003e The two probability distributions described above are *not* the same (note the difference in supports). Here we will take the first distribution described as convention.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a geometric [random variable](statistics/random-variable.md) with parameter $p$ where $0 \u003c p \u003c 1$; that is, $X \\sim \\text{Geo}(p)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = p(1 - p)^{x-1}$$\nfor a positive integer $x$ (number of trials needed before success), and $0$ otherwise. Also, $X$ has [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = 1 - (1 - p)^{\\lfloor x \\rfloor}$$\nfor $x \\geq 1$, and $0$ otherwise.\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = \\frac{1}{p}.$$\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = \\frac{1 - p}{p^2}.$$\n\n### Memoryless Property\nThe geometric distribution is memoryless; that is, if no success has been observed yet, the number of failures that has occurred does not affect the number of additional trials required to obtain the next success. Mathematically, this is described as\n$$\\mathbb{P}(X \u003e m + n | X \u003e n) = \\mathbb{P}(X \u003e m).$$\nThis can be seen by evaluating the conditional probability on the left:\n$$\\begin{align*}\n\\mathbb{P}(X \u003e m + n | X \u003e n) \u0026= \\frac{\\mathbb{P}(\\lbrace X \u003e m + n \\rbrace \\cap \\lbrace X \u003e n\\rbrace)}{\\mathbb{P}(X \u003e n)} \\\\\n\u0026= \\frac{\\mathbb{P}(X \u003e m + n)}{\\mathbb{P}(X \u003e n)} \\\\\n\u0026= \\frac{(1 - p)^{m+n}}{(1 - p)^n} \\\\\n\u0026= (1 - p)^m \\\\\n\u0026= \\mathbb{P}(X \u003e m).\n\\end{align*}$$\n\n\n\u003e [!info] Aside.\n\u003e \n\u003e The geometric distribution is the only discrete probability distribution with the memoryless property; the only continuous probability distribution with the memoryless property is the exponential distribution *\\[link needed\\]*.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/hypergeometric-distribution":{"title":"Hypergeometric Distribution","content":"\n## Definition\nThe *hypergeometric distribution* with parameters $N$, $n$, and $r$ is the discrete probability distribution of the number of successes (where a success is defined as drawing an object with some certain feature) in $n$ repetitions of drawing without replacement from some population of size $N$ where $r$ objects have the desired feature.\n\nA similar distribution is the [binomial distribution](statistics/binomial-distribution.md), which describes the probability distribution of the number of successes in $n$ repetitions of drawing *with* replacement.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a hypergeometric [random variable](statistics/random-variable.md) with parameters $N, n$, and $r$; that is, $X \\sim \\text{Hyp}(n, r, N)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\frac{\\binom{r}{x} \\binom{N - r}{n - x}}{\\binom{N}{n}},$$\nfor $\\max \\lbrace 0, r + n - N \\rbrace \\leq x \\leq \\min \\lbrace n, r \\rbrace$, and $0$ otherwise.\n\n\u003e [!tip] Tip.\n\u003e \n\u003e To reason about the form of this pmf, consider that there are $\\binom{N}{n}$ total possible outcomes, each of which are equally likely. For each number $x$ of successes, there are $\\binom{r}{x}$ ways of choosing $x$ objects (with the desired feature) from $r$ and $\\binom{N-r}{n-x}$ ways of choosing $n - x$ objects (without the desired feature) from $N - r$.\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = n \\frac{r}{N}.$$\nCompare this with the expectation of a $\\text{Bin}(n, p)$ random variable, $np$.\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = n\\frac{r}{N}\\left(1 - \\frac{r}{N}\\right)\\frac{N - n}{N - 1}.$$\nCompare this with the variance of a $\\text{Bin}(n, p)$ random variable, $np(1 - p)$.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/independence":{"title":"Independence","content":"\n## Definition\nTwo [events](statistics/event.md) $A$ and $B$ are said to be *independent* if $\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)$.\n\nA collection of events $A_1, A_2, \\dots$ is said to be *pairwise independent* if, for all $i \\neq j$, $A_i$ and $A_j$ are independent; that is, $\\mathbb{P}(A_i \\cap A_j) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)$. \\\nThey are said to be *triplewise independent* if, for all distinct $i, j, k$, we have $\\mathbb{P}(A_i \\cap A_j \\cap A_k) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)\\mathbb{P}(A_k)$.\n\nGenerally, they are said to be *mutually independent* if each event is independent of any combination of other events in the collection; that is, $$\\mathbb{P}\\left(\\bigcap_i A_i \\right) = \\prod_i \\mathbb{P}(A_i).$$\n\n## Properties\n\nIf $A$ and $B$ are independent events, then $A^c$ and $B^c$ are independent, i.e. $\\mathbb{P}(A^c \\cap B^c) = \\mathbb{P}(A^c)\\mathbb{P}(B^c)$. \\\n**Proof.** Using [De Morgan's Law](statistics/de-morgans-laws.md), we have $\\mathbb{P}(A^c \\cap B^c) = \\mathbb{P}((A \\cup B)^c)$. Then\n$$\\begin{align*}\n\\mathbb{P}(A^c \\cap B^c) \u0026= 1 - \\mathbb{P}(A \\cup B) \\\\\n\u0026= 1 - [\\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)] \\\\\n\u0026= 1 - [\\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A)\\mathbb{P}(B)] \u0026\u0026 A, B \\text{ independent} \\\\\n\u0026= 1 - \\mathbb{P}(A) - \\mathbb{P}(B) + \\mathbb{P}(A)\\mathbb{P}(B) \\\\\n\u0026= (1 - \\mathbb{P}(A))(1 - \\mathbb{P}(B)) \\\\\n\u0026= \\mathbb{P}(A^c)\\mathbb{P}(B^c).\n\\end{align*}$$\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/law-of-the-unconscious-statistician":{"title":"Law of the Unconscious Statistician","content":"\n## Definition\nLet $X$ be a [discrete random variable](statistics/random-variable.md) with support $S$ and with [probability mass function](statistics/probability-mass-function.md) $f_X(x)$ where $x \\in S$, and let $g(X)$ be some function of $X$. Then the [expectation](statistics/expectation.md) of $g(X)$ is given by\n$$\\mathbb{E}(g(X)) = \\sum_{x \\in S} g(x)f_X(x) = \\sum_{x \\in S} g(x) \\mathbb{P}(X = x).$$\n\nIf $X: \\Omega \\to \\mathbb{R}$ is a continuous random variable with [probability density function](statistics/probability-density-function.md) $f_X(x)$ where $x \\in \\Omega$, and let $g(X)$ be some function of $X$. Then the expectation of $g(X)$ is given by\n$$\\mathbb{E}(g(X)) = \\int_{-\\infty}^\\infty g(x)f_X(x) dx$$\n\nThe Law of the Unconscious Statistician is often shortened to LOTUS.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/law-of-total-probability":{"title":"Law of Total Probability","content":"\n## Definition\nIf $A$ and $B$ are [events](statistics/event.md) such that $0 \u003c \\mathbb{P}(B) \u003c 1$, then\n$$\\mathbb{P}(A) = \\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c).$$\nMore generally, if $\\lbrace B_i \\rbrace$ is a collection of events that form a [partition](statistics/partition.md) of $\\Omega$ such that $\\mathbb{P}(B_i) \u003e 0$ for at least one $i$,  then\n$$\\mathbb{P}(A) = \\sum_i \\mathbb{P}(A|B_i)\\mathbb{P}(B_i) = \\sum_i \\mathbb{P}(A \\cap B_i)$$\nfor any event $A$, by the definition of [conditional probability](statistics/conditional-probability.md).\n\n## Proof\nWe have\n$$A = A \\cap \\Omega = A \\cap (B \\cup B^c) = (A \\cap B) \\cup (A \\cap B^c),$$\nwhere $A \\cap B$ and $A \\cap B^c$ are disjoint events. Then from the [third axiom of probability](statistics/probability-measure.md) and the definition of conditional probability,\n$$\\mathbb{P}(A) = \\mathbb{P}(A \\cap B) + \\mathbb{P}(A \\cap B^c) = \\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c).$$\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/markovs-inequality":{"title":"Markov's Inequality","content":"\n## Definition\nLet $X$ be a non-negative [random variable](statistics/random-variable.md) (i.e. $X \\geq 0$) and $a \u003e 0$. Then\n$$\\mathbb{P}(X \\geq a) \\leq \\frac{\\mathbb{E}(X)}{a}.$$\n\n## Proof\nDefine $A = \\lbrace \\omega \\in \\Omega : X(\\omega) \\geq a \\rbrace$. Then the random variable $X - a \\cdot \\mathbb{I}_A \\geq 0$, since if the outcome is in $A$, $X \\geq a$ and $a - a \\cdot \\mathbb{I}_A = 0$ implies $X \\geq a \\cdot \\mathbb{I}_A$, and if the outcome is not in $A$, $\\mathbb{I}_A = 0$ which implies $X - a \\cdot \\mathbb{I}_A = X \\geq 0$. Taking the [expectation](statistics/expectation.md) of this random variable yields\n$$\\begin{align*}\n\\mathbb{E}(X - a \\cdot \\mathbb{I}_A) \u0026\\geq 0 \\\\\n\\mathbb{E}X - a \\cdot \\mathbb{E}(\\mathbb{I}_A) \u0026\\geq 0 \\\\\n\\mathbb{E}X - a \\cdot \\mathbb{P}(A) \u0026\\geq 0 \\\\\na \\cdot \\mathbb{P}(A) \u0026\\leq \\mathbb{E}X \\\\\n\\therefore \\mathbb{P}(A) \\leq \\frac{\\mathbb{E}X}{a}.\n\\end{align*}$$\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/moment":{"title":"Moment","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the n-th *moment* of $X$ is given by $\\mathbb{E}(X^n)$.\n\nFor example, the [expectation](statistics/expectation.md) of $X$ is the first moment of $X$, and the [variance](statistics/variance.md) of $X$ is the second moment of $X$ minus the square of the first moment of $X$.\n\n\u003e [!info] Aside.\n\u003e \n\u003e There are also other types of moments. For an arbitrary random variable $X$,\n\u003e - $\\mathbb{E}((X - \\mu_X)^n)$ is called the n-th *central moment* of $X$. For example, the variance of $X$ is the second central moment of $X$.\n\u003e - $\\mathbb{E}(((X - \\mu_X)/\\sigma_X)^n)$ is called the n-th *standardized moment* of $X$. For example, the third standardized moment of $X$ is called the *skewness* of $X$.\n\u003e - $\\mathbb{E}(X(X - 1)\\cdots(X - (n - 1)))$ is called the n-th *factorial moment* of $X$.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/moment-generating-function":{"title":"Moment Generating Function","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the *moment generating function* (MGF) of $X$ is defined as\n$$M(t) = \\mathbb{E}(e^{tX}), \\quad t \\in \\mathbb{R}$$\nprovided the expectation exists on some open interval $I$ containing 0, where we often write $M_X(z)$ to emphasize the role of $X$ (especially with dealing with multiple MGFs).\n\nIf $X$ is a discrete random variable with range $S$,\n$$M_X(t) = \\sum_{x \\in S} e^{tx}f_X(x), \\quad t \\in I$$\nand if $X$ is a continuous random variable,\n$$M_X(t) = \\int_{-\\infty}^\\infty e^{tx} f_X(x) dx, \\quad t \\in I.$$\n\n\u003e [!warning] Note.\n\u003e \n\u003e If $X$ is a non-negative discrete random variable (that is, it takes values in the non-negative integers), then $M_X(t) = G_X(e^t)$ for $t \\in I$, where $G_X$ is the [PGF](statistics/probability-generating-function.md) of $X$, in which case we would usually use PGFs over MGFs.\n\n## Properties\nLet $X$ be an arbitrary random variable with MGF $M(t)$. Then $M$ has the following properties:\n1. $M$ determines the distribution of $X$ uniquely; two MGFs are the same if and only if their [cumulative distribution functions](statistics/cumulative-distribution-function.md) are the same.\n2. The [expectation](statistics/expectation.md) of $X$ is given by $\\mathbb{E}X = M'(0)$.\n3. More generally, $\\mathbb{E}(X^n) = M^{(n)}(0), n \\geq 1$, i.e. $M^{(n)}(0)$ gives the n-th [moment](statistics/moment.md) of $X$.\n4. From 2 and 3, we have that the [variance](statistics/variance.md) of $X$ is given by $\\text{Var}(X) = M''(0) - (M'(0))^2$.","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/partition":{"title":"Partition","content":"\n## Definition\n[Events](statistics/event.md) $A_1, A_2, \\dots$ are said to be *exhaustive* if $A_1 \\cup A_2 \\cup \\cdots = \\Omega$, that is at least one $A_i$ must occur.\n\nIf $A_1, A_2, \\dots$ are exhaustive and mutually exclusive (i.e. they cannot occur simultaneously), then they are a *partition* of $\\Omega$ and are said to partition the sample space.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/poisson-distribution":{"title":"Poisson Distribution","content":"\n## Definition\nThe *Poisson distribution* with parameter $\\lambda \u003e 0$ (mean rate) is the discrete probability distribution of the number of events occurring in a fixed time interval where the mean rate of occurrences is constant and events occur independently of the time of the previous event.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a Poisson [random variable](statistics/random-variable.md) with parameter $\\lambda \u003e 0$; that is, $X \\sim \\text{Poi}(\\lambda)$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\mathbb{P}(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}$$\nfor a non-negative integer $x$ (number of occurrences), and $0$ otherwise.\n\n### Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = \\lambda.$$\n\n### Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\text{Var}(X) = \\lambda.$$\n\n### Connection to binomial distribution\nThe Poisson $\\text{Poi}(np)$ distribution is the limiting distribution of a [binomial](statistics/binomial-distribution.md) $\\text{Bin}(n, p)$ distribution. To see this, suppose $X \\sim \\text{Bin}(n, p)$ and let $\\lambda = np \u003e 0$. Now let the number of trials $n$ tend to infinity, whilst holding the product $np$ constant. The expectation of $X$ is given by\n$$\\mathbb{E}X = np = \\lambda,$$\nand the variance of $X$ is given by\n$$\\text{Var}(X) = np(1 - p) = n \\left(\\frac{\\lambda}{n}\\right) \\left(1 - \\frac{\\lambda}{n}\\right) = \\lambda \\left(1 - \\frac{\\lambda}{n}\\right),$$\nwhich tends to $\\lambda$ as $n \\to \\infty$. The pmf of $X$, for support $x \\in 0, 1, 2, \\dots$, is given by\n$$\\begin{align*}\n\\mathbb{P}(X = x) \u0026= \\binom{n}{x} \\left(\\frac{\\lambda}{n}\\right)^x \\left(1 - \\frac{\\lambda}{n}\\right)^{n-x} \\\\\n\u0026= \\frac{n \\times (n - 1) \\times \\cdots \\times (n - x + 1)}{x!} \\frac{\\lambda^x}{n^x} \\left(1 - \\frac{\\lambda}{n}\\right)^n \\left(1 - \\frac{\\lambda}{n}\\right)^{-x},\n\\end{align*}$$\nwhere we can take the limits of each component separately:\n$$\\lim_{n\\to\\infty} \\left(\\frac{n \\times (n - 1) \\times \\cdots \\times (n - x + 1)}{x!} \\frac{\\lambda^x}{n^x}\\right) = \\frac{\\lambda^x}{x!}$$\n$$\\lim_{n\\to\\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^n = e^{-\\lambda}$$\n$$\\lim_{n\\to\\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{-x} = 1,$$\nyielding\n$$\\mathbb{P}(X = x) \\to \\frac{\\lambda^x e^{-\\lambda}}{x!},$$\nwhich is precisely the pmf of a Poisson random variable.\n\nIt follows that the Poisson $\\text{Poi}(np)$ distribution approximates the binomial $\\text{Bin}(n, p)$ distribution when $n$ is sufficiently large and $p$ is sufficiently small. A good rule of thumb is to have $n \\geq 20$ and $p \\leq 0.05$.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/probability-density-function":{"title":"Probability Density Function","content":"\n## Definition\nIf $X: \\Omega \\to \\mathbb{R}$ is a *continuous [random variable](statistics/random-variable.md)*, then the function $f$ such that $f(x) \\geq 0$ for all $x \\in \\Omega$ and\n$$\\mathbb{P}(x \\leq X \\leq y) = \\int_x^y f(u)du$$\nfor all $x \\leq y$, that is, the probability that $X$ takes on values in the interval $[x, y]$ is given by the area under the graph of the pdf from $x$ to $y$. It is often denoted $f_X(x).$\n\n\u003e [!warning] Note.\n\u003e \n\u003e Note that $f(x)$ is *not* a probability; it should be thought of as a *probability density*. It is not true that $f(x) = \\mathbb{P}(X = x)$ for all $x$. In fact, we have $\\mathbb{P}(X = x) = 0$ for all $x$ in the support of $X$.\n\n## Properties\nIf $X$ is a continuous random variable taking values in $\\Omega$, then\n1. $f_X(x) \\geq 0$ for all real $x$\n2. $\\int_{-\\infty}^\\infty f_X(u) du = 1$\n3. $F_X(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(u) du$, where $F_X(x)$ is the [cumulative distribution function](statistics/cumulative-distribution-function.md). Additionally, if $f_X(x)$ exists, $F'_X(x) = f_X(x)$.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/probability-generating-function":{"title":"Probability Generating Function","content":"\n## Definition\nLet $X$ be a non-negative [discrete random variable](statistics/random-variable.md). Then the *probability generating function* (PGF) of $X$ is defined as\n$$G(z) = \\mathbb{E}(z^X) = \\sum_{k=0}^\\infty z^k \\mathbb{P}(X = k), \\quad |z| \\leq 1,$$\nwhere we often write $G_X(z)$ to emphasize the role of $X$ (especially when dealing with multiple PGFs).\n\nMathematically, $G$ is a *power series* *\\[link needed\\]* with coefficients $a_k = \\mathbb{P}(X = k)$, and converges *\\[link needed\\]* for all $|z| \\leq 1$ and often for $|z| \\leq R$ where $R \u003e 1$. As such, it can be differentiated or integrated term-wise.\n\n## Properties\nLet $X$ be a non-negative discrete random variable with PGF $G(z)$. Then $G$ has the following properties:\n1. $G$ determines the distribution of $X$ uniquely with\n   $$\\mathbb{P}(X = k) = \\frac{G^{(k)}(0)}{k!}, \\quad k \\geq 1.$$\n2. The [expectation](statistics/expectation.md) of $X$ is given by $\\mathbb{E}X = G'(1)$.\n3. More generally, $\\mathbb{E}(X(X - 1)\\cdot(X - (k - 1))) = G^{(k)}(1), k \\geq 1$, i.e. $G^{(k)}(1)$ gives the k-th [factorial moment](statistics/moment.md) of $X$.\n4. From 2 and 3, we have that the [variance](statistics/variance.md) of $X$ is given by $\\text{Var}(X) = G''(1) + G'(1) - (G'(1))^2$.\n\n\u003e [!warning] Note.\n\u003e \n\u003e $G'(1)$ (and $G^{(k)}(1)$ etc.) may not be defined if $R = 1$, in which case we conventionally take $G(1)$ to be the limit from below, i.e. $G(1) = \\lim_{z\\to1^-} G(z)$.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/probability-mass-function":{"title":"Probability Mass Function","content":"\n## Definition\nIf $X$ is a *discrete [random variable](statistics/random-variable.md)*, then the function\n$$f(x) = \\mathbb{P}(X = x)$$\nis the *probability (mass) function* of $X$. It is often denoted $f_X(x)$.\n\n## Properties\nIf $X$ is a discrete random variable taking values in $S$, then\n1. $f_X(x) \\geq 0$ for all real $x$\n2. $\\sum_{x\\in S} f_X(x) = 1$.\n3. $F_X(x) = \\mathbb{P}(X \\leq x) = \\sum_{y \\in S | y \\leq x} f_X(y)$, where $F_X(x)$ is the [cumulative distribution function](statistics/cumulative-distribution-function.md).","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/probability-measure":{"title":"Probability Measure","content":"\n## Definition\nThe function $\\mathbb{P}$ is called a *probability measure* if it satisfies the following properties, or *axioms*:\n1. $\\mathbb{P}(A) \\geq 0$ for all events $A$\n2. $\\mathbb{P}(\\Omega) = 1$\n3. If $A_1, A_2, \\dots$ are [mutually exclusive events](statistics/event.md), then $\\mathbb{P}(A_1 \\cup A_2 \\cup \\cdots) = \\mathbb{P}(A_1) + \\mathbb{P}(A_2) + \\cdots$\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/random-variable":{"title":"Random Variable","content":"\n## Definition\nA random variable $X$ is a function or mapping from the possible outcomes in a [sample space](statistics/sample-space.md) to numerical values, usually the real numbers.\n\nA random variable is said to be *discrete* if it takes values in (i.e. maps to) a countable set.\n\nA random variable is said to be *continuous* if it takes values in (i.e. maps to) an *interval*.\n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/sample-space":{"title":"Sample Space","content":"\n## Definition\nThe set $\\Omega$ of all possible outcomes of an experiment or random trial is called the *sample space*. \n","lastmodified":"2023-02-14T09:20:24.845978359Z","tags":null},"/statistics/uniform-distribution":{"title":"Uniform Distribution","content":"\n## Definition\nThe *uniform distribution* is the continuous probability distribution that takes on values in the support $[a, b]$ (or $(a, b)$ for an open interval) such that all intervals (contained in the support) of the same length have equal probability. A random variable $X$ that is uniformly distributed on $[a, b]$ satisfies\n$$\\mathbb{P}(x \\leq X \\leq y) = \\frac{y - x}{b - a}, a \\leq x \\leq y \\leq b,$$\nthat is the probability of taking on a value in a particular interval is directly proportional to the interval's length.\n\n## Properties\n### Probability Mass Function\nLet $X$ be a uniform [random variable](statistics/random-variable.md) on $[a, b]$. Then $X$ has [pmf](statistics/probability-mass-function.md)\n$$f_X(x) = \\begin{cases}\n\\frac{1}{b-a}, \u0026 \\text{if } a \\leq x \\leq b \\\\\n0, \u0026 \\text{otherwise.}\n\\end{cases}$$\nand [cdf](statistics/cumulative-distribution-function.md)\n$$F_X(x) = \\mathbb{P}(X \\leq x) = \\begin{cases}\n0, \u0026 \\text{if } x \u003c a \\\\\n\\frac{x - a}{b - a}, \u0026 \\text{if } a \\leq x \\leq b \\\\\n1, \u0026 \\text{if } x \u003e b.\n\\end{cases}$$\n\n## Expectation\nThe [expectation](statistics/expectation.md) of $X$ is given by\n$$\\mathbb{E}X = \\frac{1}{b-a} \\int_a^b x dx = \\frac{b^2 - a^2}{2(b - a)} = \\frac{a + b}{2},$$\nwhich intuitively makes sense as it is the mean of the bounds $a$ and $b$.\n\n## Variance\nThe [variance](statistics/variance.md) of $X$ is given by\n$$\\begin{align*}\n\\text{Var}(X) \u0026= \\mathbb{E}(X^2) - (\\mathbb{E}X)^2 \\\\\n\u0026= \\frac{1}{b - a}\\int_a^b x^2dx - \\left(\\frac{a + b}{2}\\right)^2 \\\\\n\u0026= \\frac{a^2 + ab + b^2}{3} - \\frac{a^2 + 2ab + b^2}{4} \\\\\n\u0026= \\frac{(b - a)^2}{12},\n\\end{align*}$$\nwhere we use difference of cubes in the third step.\n","lastmodified":"2023-02-14T09:20:24.849978362Z","tags":null},"/statistics/variance":{"title":"Variance","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the *variance* of $X$, denoted $\\text{Var}(X)$, is given by\n$$\\text{Var}(X) = \\mathbb{E}(X - \\mu_X)^2,$$ and quantities the spread of the distribution of $X$, or the variation about the mean, $\\mu_X$.\n\nThe variance may also be written as:\n$$\\text{Var}(X) = \\mathbb{E}(X - \\mu_X)^2 = \\mathbb{E}(X^2) - 2\\mu_x\\mathbb{E}X + \\mu_X^2 = \\mu_X^2 = \\mathbb{E}(X^2) - \\mu_X^2.$$\n\nThe variance of $X$ is also commonly denoted by $\\sigma_X^2$, where $\\sigma_X$ is the *standard deviation* of $X$.\n\n## Properties\nIf $X$ is any arbitrary random variable, then $\\text{Var}(aX + b) = a^2\\text{Var}(X)$ for all $a$ and $b$. \\\n**Proof.** We have\n$$\\begin{align*}\n\\text{Var}(aX + b) \u0026= \\mathbb{E}(aX + b)^2 - (\\mathbb{E}(aX + b))^2 \\\\\n\u0026= \\mathbb{E}(a^2X^2 + 2abX + b^2) - (a\\mathbb{E}X + b)^2 \\\\\n\u0026= \\mathbb{E}(a^2X^2 + 2abX + b^2) - (a^2(\\mathbb{E}X)^2 + 2ab\\mathbb{E}X + b^2) \\\\\n\u0026= a^2(\\mathbb{E}(X^2) - (\\mathbb{E}X)^2) \\\\\n\u0026= a^2\\text{Var}(X)\n\\end{align*}$$\n","lastmodified":"2023-02-14T09:20:24.849978362Z","tags":null}}
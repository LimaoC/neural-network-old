{"/":{"title":"Neural Network","content":"\nHello, and welcome to my neural network! This is where I store my second brain - filled with notes from my mathematics and computer science degrees.","lastmodified":"2022-11-21T13:27:36.408633341Z","tags":null},"/statistics/booles-inequality":{"title":"Boole's Inequality","content":"\nFor any [events](statistics/event.md) $A_1, A_2, \\dots$, we have\n$$\\mathbb{P}\\left(\\bigcup_i A_i\\right) \\leq \\sum_i \\mathbb{P}(A_i).$$\nThat is, the probability that at least one of the events occurs is less than or equal to the sum of the probabilities of the individual events.\n\n\u003e [!note] Proof.\n\u003e \n\u003e We proceed by induction. The $n = 1$ case holds, since $\\mathbb{P}(A_1) \\leq \\mathbb{P}(A_1)$. \\\n\u003e Assume the $n = k$ case holds; that is,\n\u003e $$\\mathbb{P}\\left(\\bigcup_{i=1}^k A_i\\right) \\leq \\sum_{i=1}^k \\mathbb{P}(A_i).$$\n\u003e Then, using $\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)$, \n\u003e $$\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) = \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) - \\mathbb{P}\\left(\\left(\\bigcup_{i=1}^n A_i \\right) \\bigcap A_{k+1} \\right),$$\n\u003e and since $\\mathbb{P}(E) \\geq 0$ for any event $E$ (from the [probability axioms](statistics/probability-measure.md)),\n\u003e $$\\begin{align*}\n\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) \u0026\\leq \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026\\leq \\sum_{i=1}^k \\mathbb{P}(A_i) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026= \\sum_{i=1}^{k+1} \\mathbb{P}(A_i).\n\\end{align*}$$\n","lastmodified":"2022-11-21T13:27:36.408633341Z","tags":null},"/statistics/de-morgans-laws":{"title":"De Morgan's Laws","content":"\n\u003e [!abstract] Theorem.\n\u003e \n\u003e Let $\\lbrace A_i \\rbrace$ be a collection of [events](statistics/event.md). Then\n\u003e $$\\left(\\bigcup_i A_i\\right)^c = \\bigcap_i A_i^c \\quad\\text{and}\\quad\\left(\\bigcap_i A_i\\right)^c = \\bigcup_i A_i^c.$$\n","lastmodified":"2022-11-21T13:27:36.408633341Z","tags":null},"/statistics/event":{"title":"Event","content":"\n\u003e [!abstract] Definition.\n\u003e \n\u003e An *event* is any subset of outcomes; that is, any subset of the [sample space](statistics/sample-space.md) $\\Omega$.\n\nLet $\\lbrace A_i \\rbrace$ be a collection of events. \\\nThe *union* of $\\lbrace A_i \\rbrace$, denoted $\\cup_i A_i = A_1 \\cup A_2 \\cup \\cdots$, is the event that $A_i$ occurs for at least one value of $i$. \\\nThe *intersection* of $\\lbrace{A_i \\rbrace}$, denoted $\\cap_iA_i = A_1 \\cap A_2 \\cap \\cdots$, is the event that $A_i$ occurs for all values of $i$.\n\nIf $A$ is an event, then $A$ complement, denoted $A^c$, is the event that $A$ does not occur.\n\nIf $A$ and $B$ are two events such that $A \\neq B$, and all the outcomes in $A$ are also in $B$, then $A$ is a *proper subset* of $B$, denoted $A \\subset B$. If $A$ and $B$ are equal, then $A$ is a *subset* of $B$, denoted $A \\subseteq B$. $A \\subset B$ can also be read as \"$A$ implies $B$\". Note that \"subset\" is often said as as shorthand of \"proper subset\" when $A \\subset B$ is used.\n\nIf $A$ and $B$ are two events such that they share no outcomes in common, they are said to be *disjoint*, that is $A \\cap B = \\varnothing$. More generally, $A_1, A_2, \\dots$ is said to be *disjoint* if each pair of events $(A_i, A_j$) with $i \\neq j$, is disjoint.\n\n$A_1, A_2, \\dots$ are said to be *exhaustive* if $A_1 \\cup A_2 \\cup \\cdots = \\Omega$, that is at least one $A_i$ must occur. If $A_1, A_2, \\dots$ are exhaustive and mutually exclusive, then they are a *partition* of $\\Omega$ and are said to partition the sample space.\n","lastmodified":"2022-11-21T13:27:36.408633341Z","tags":null},"/statistics/independence":{"title":"Independence","content":"\n\u003e [!abstract] Definition.\n\u003e \n\u003e Two [events](statistics/event.md) $A$ and $B$ are said to be *independent* if $\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)$.\n\u003e \n\u003e A collection of events $A_1, A_2, \\dots$ is said to be *pairwise independent* if, for all $i \\neq j$, $A_i$ and $A_j$ are independent; that is, $\\mathbb{P}(A_i \\cap A_j) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)$. \\\n\u003e They are said to be *triplewise independent* if, for all distinct $i, j, k$, we have $\\mathbb{P}(A_i \\cap A_j \\cap A_k) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)\\mathbb{P}(A_k)$.\n\u003e \n\u003e Generally, they are said to be *mutually independent* if each event is independent of any combination of other events in the collection; that is, $$\\mathbb{P}\\left(\\bigcap_i A_i \\right) = \\prod_i \\mathbb{P}(A_i).$$\n","lastmodified":"2022-11-21T13:27:36.408633341Z","tags":null},"/statistics/probability-measure":{"title":"Probability Measure","content":"\n\u003e [!abstract] Definition.\n\u003e \n\u003e The function $\\mathbb{P}$ is called a *probability measure* if it satisfies the following properties or *axioms*:\n\u003e 1. $\\mathbb{P}(A) \\geq 0$ for all events $A$\n\u003e 2. $\\mathbb{P}(\\Omega) = 1$\n\u003e 3. If $A_1, A_2, \\dots$ are [mutually exclusive events](statistics/event.md), then $\\mathbb{P}(A_1 \\cup A_2 \\cup \\cdots) = \\mathbb{P}(A_1) + \\mathbb{P}(A_2) + \\cdots$\n","lastmodified":"2022-11-21T13:27:36.408633341Z","tags":null},"/statistics/sample-space":{"title":"Sample Space","content":"\n\u003e [!abstract] Definition.\n\u003e \n\u003e The set $\\Omega$ of all possible outcomes of an experiment or random trial is called the *sample space*. \n\nSubsets of the sample space are known as [events](statistics/event.md).\n","lastmodified":"2022-11-21T13:27:36.408633341Z","tags":null}}
{"/":{"title":"Neural Network","content":"\nHello, and welcome to my neural network! This is where I store my second brain - filled with notes from my mathematics and computer science degrees.","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/bayes-theorem":{"title":"Bayes' Theorem","content":"\n## Definition\nLet $A$ and $B$ be arbitrary [events](statistics/event.md) such that $\\mathbb{P}(A) \u003e 0$ and $0 \u003c \\mathbb{P}(B) \u003c 1$. Then\n$$\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)} = \\frac{\\mathbb{P}(A|B)\\mathbb{P}(B)}{\\mathbb{P}(A)},$$\nusing the definition of [conditional probability](statistics/conditional-probability.md) twice and the [Law of Total Probability](statistics/law-of-total-probability.md).\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/booles-inequality":{"title":"Boole's Inequality","content":"\n## Definition\nFor any [events](statistics/event.md) $A_1, A_2, \\dots$, we have\n$$\\mathbb{P}\\left(\\bigcup_i A_i\\right) \\leq \\sum_i \\mathbb{P}(A_i).$$\nThat is, the probability that at least one of the events occurs is less than or equal to the sum of the probabilities of the individual events.\n\n## Proof\nWe proceed by induction. The $n = 1$ case holds, since $\\mathbb{P}(A_1) \\leq \\mathbb{P}(A_1)$. Then assume the $n = k$ case holds; that is,\n$$\\mathbb{P}\\left(\\bigcup_{i=1}^k A_i\\right) \\leq \\sum_{i=1}^k \\mathbb{P}(A_i).$$\nUsing $\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)$, \n$$\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) = \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) - \\mathbb{P}\\left(\\left(\\bigcup_{i=1}^n A_i \\right) \\bigcap A_{k+1} \\right),$$\nand since $\\mathbb{P}(E) \\geq 0$ for any event $E$ ([first axiom of probability](statistics/probability-measure.md)),\n$$\\begin{align*}\n\\mathbb{P}\\left(\\bigcup_{i=1}^{k+1} A_i \\right) \u0026\\leq \\mathbb{P}\\left(\\bigcup_{i=1}^k A_i \\right) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026\\leq \\sum_{i=1}^k \\mathbb{P}(A_i) + \\mathbb{P}(A_{k+1}) \\\\\n\u0026= \\sum_{i=1}^{k+1} \\mathbb{P}(A_i).\n\\end{align*}$$\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/conditional-probability":{"title":"Conditional Probability","content":"\n## Definition\nThe [event](statistics/event.md) that $A$ occurs, given that we know $B$ has occurred, is denoted $A | B$. We have\n$$\\mathbb{P}(A | B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)},$$\nwhere $\\mathbb{P}(B \u003e 0)$. \n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/cumulative-distribution-function":{"title":"Cumulative Distribution Function","content":"\n## Definition\nIf $X$ is an arbitrary [random variable](statistics/random-variable.md), then the function\n$$F(x) = \\mathbb{P}(X \\leq x)$$\nis the *(cumulative) distribution function* of $X$. It is often denoted $F_X(x)$.\n\n## Properties\nLet $X$ be a random variable. Then the distribution function $F$ has the following properties:\n1. $F(x) \\to 0$ as $x \\to -\\infty$.\n2. $F(x) \\to 1$ as $x \\to \\infty$.\n3. $F$ is an increasing function; that is $x \u003e y \\implies F(x) \\geq F(y)$.\n4. $F$ is continuous from the right; that is, for all $x$, $F(x + h) \\to F(x)$ as $h \\downarrow 0$ (limit from above).\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/de-morgans-laws":{"title":"De Morgan's Laws","content":"\n## Definition\nLet $\\lbrace A_i \\rbrace$ be a collection of [events](statistics/event.md). Then\n$$\\left(\\bigcup_i A_i\\right)^c = \\bigcap_i A_i^c \\quad\\text{and}\\quad\\left(\\bigcap_i A_i\\right)^c = \\bigcup_i A_i^c.$$\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/disjoint-event":{"title":"Disjoint Event","content":"\n## Definition\nIf $A$ and $B$ are two [events](statistics/event.md) such that they share no outcomes in common, they are said to be *disjoint*, that is $A \\cap B = \\varnothing$. More generally, $A_1, A_2, \\dots$ is said to be *disjoint* if each pair of events $(A_i, A_j$) with $i \\neq j$, is disjoint.\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/event":{"title":"Event","content":"\n## Definition\nAn *event* is any subset of outcomes; that is, any subset of the [sample space](statistics/sample-space.md) $\\Omega$.\n\nIf $A$ is an event, then $A$ complement, denoted $A^c$, is the event that $A$ does not occur.\n\nLet $\\lbrace A_i \\rbrace$ be a collection of events. \\\nThe *union* of $\\lbrace A_i \\rbrace$, denoted $\\cup_i A_i = A_1 \\cup A_2 \\cup \\cdots$, is the event that $A_i$ occurs for at least one value of $i$. \\\nThe *intersection* of $\\lbrace{A_i \\rbrace}$, denoted $\\cap_iA_i = A_1 \\cap A_2 \\cap \\cdots$, is the event that $A_i$ occurs for all values of $i$.\n\nIf $A$ and $B$ are two events such that $A \\neq B$, and all the outcomes in $A$ are also in $B$, then $A$ is a *proper subset* of $B$, denoted $A \\subset B$. If $A$ and $B$ are equal, then $A$ is a *subset* of $B$, denoted $A \\subseteq B$. $A \\subset B$ can also be read as \"$A$ implies $B$\". Note that \"subset\" is often said as a shorthand of \"proper subset\" when $A \\subset B$ is used.\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/expectation":{"title":"Expectation","content":"\n## Definition\nLet $X$ be a [discrete random variable](statistics/random-variable.md) with [probability mass function](statistics/probability-mass-function.md) $f_X(x)$ where $x \\in S$. Then the expected value of $X$, denoted by $\\mathbb{E}(X)$ and commonly shortened to $\\mathbb{E}X$, is given by\n$$\\mathbb{E}(X) = \\sum_{x \\in S} xf_X(x) = \\sum_{x \\in S} x\\mathbb{P}(X = x).$$\n\nLet $X$ be a continuous random variable with [probability density function](statistics/probability-density-function.md) $f_X(x)$. Then the expected value of $X$ is given by\n$$\\mathbb{E}(X) = \\int_{-\\infty}^\\infty uf(u)du.$$\n\nThe expected value of $X$ is also commonly denoted by $\\mu_X$.\n\n\u003e [!tip] Tip.\n\u003e \n\u003e Intuitively, the expectation of a random variable $X$ is a weighted average of the values that $X$ takes ($x$ in the range of $X$), where the weight is given by the probability of each value in the discrete case, and the density function $f_X$ in the continuous case.\n\n## Properties\nLet $X$ and $Y$ be two arbitrary random variables. Then\n1. $\\mathbb{E}(aX + b) = a\\mathbb{E}X + b$ for all $a, b$\n2. $\\mathbb{E}(X + Y) = \\mathbb{E}X + \\mathbb{E}Y$\n3. $X \\geq Y \\implies \\mathbb{E}X \\geq \\mathbb{E}Y$\n\n**Proof.** The first property follows from applying [LOTUS](statistics/law-of-the-unconscious-statistician.md). For the second property, first define $X: \\Omega \\to \\mathbb{R}$, $Y: \\Omega \\to \\mathbb{R}$ and $Z(\\omega) = X(\\omega) + Y(\\omega)$. Then\n$$\\begin{align*}\n\\mathbb{E}Z \u0026= \\sum_{\\omega\\in\\Omega} Z(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\sum_{\\omega\\in\\Omega} (X(\\omega) + Y(\\omega)) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\sum_{\\omega\\in\\Omega} X(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) + \\sum_{\\omega\\in\\Omega} Y(\\omega) \\mathbb{P}(\\lbrace\\omega\\rbrace) \\\\\n\u0026= \\mathbb{E}X + \\mathbb{E}Y,\n\\end{align*}$$\nwith the continuous case following analogously with integrals. For the third property, $X \\geq Y \\implies X - Y \\geq 0 \\implies \\mathbb{E}(X - Y) \\geq 0 \\implies \\mathbb{E}X \\geq \\mathbb{E}Y$, where we use the second property in the last step.","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/independence":{"title":"Independence","content":"\n## Definition\nTwo [events](statistics/event.md) $A$ and $B$ are said to be *independent* if $\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)$.\n\nA collection of events $A_1, A_2, \\dots$ is said to be *pairwise independent* if, for all $i \\neq j$, $A_i$ and $A_j$ are independent; that is, $\\mathbb{P}(A_i \\cap A_j) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)$. \\\nThey are said to be *triplewise independent* if, for all distinct $i, j, k$, we have $\\mathbb{P}(A_i \\cap A_j \\cap A_k) = \\mathbb{P}(A_i)\\mathbb{P}(A_j)\\mathbb{P}(A_k)$.\n\nGenerally, they are said to be *mutually independent* if each event is independent of any combination of other events in the collection; that is, $$\\mathbb{P}\\left(\\bigcap_i A_i \\right) = \\prod_i \\mathbb{P}(A_i).$$\n\n## Properties\n\nIf $A$ and $B$ are independent events, then $A^c$ and $B^c$ are independent, i.e. $\\mathbb{P}(A^c \\cap B^c) = \\mathbb{P}(A^c)\\mathbb{P}(B^c)$. \\\n**Proof.** Using [De Morgan's Law](statistics/de-morgans-laws.md), we have $\\mathbb{P}(A^c \\cap B^c) = \\mathbb{P}((A \\cup B)^c)$. Then\n$$\\begin{align*}\n\\mathbb{P}(A^c \\cap B^c) \u0026= 1 - \\mathbb{P}(A \\cup B) \\\\\n\u0026= 1 - [\\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)] \\\\\n\u0026= 1 - [\\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A)\\mathbb{P}(B)] \u0026\u0026 A, B \\text{ independent} \\\\\n\u0026= 1 - \\mathbb{P}(A) - \\mathbb{P}(B) + \\mathbb{P}(A)\\mathbb{P}(B) \\\\\n\u0026= (1 - \\mathbb{P}(A))(1 - \\mathbb{P}(B)) \\\\\n\u0026= \\mathbb{P}(A^c)\\mathbb{P}(B^c).\n\\end{align*}$$\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/law-of-the-unconscious-statistician":{"title":"Law of the Unconscious Statistician","content":"\n## Definition\nLet $X$ be a [discrete random variable](statistics/random-variable.md) with support $S$ and with [probability mass function](statistics/probability-mass-function.md) $f_X(x)$ where $x \\in S$, and let $g(X)$ be some function of $X$. Then the [expectation](statistics/expectation.md) of $g(X)$ is given by\n$$\\mathbb{E}(g(X)) = \\sum_{x \\in S} g(x)f_X(x) = \\sum_{x \\in S} g(x) \\mathbb{P}(X = x).$$\n\nIf $X: \\Omega \\to \\mathbb{R}$ is a continuous random variable with [probability density function](statistics/probability-density-function.md) $f_X(x)$ where $x \\in \\Omega$, and let $g(X)$ be some function of $X$. Then the expectation of $g(X)$ is given by\n$$\\mathbb{E}(g(X)) = \\int_{-\\infty}^\\infty g(x)f_X(x) dx$$\n\nThe Law of the Unconscious Statistician is often shortened to LOTUS.\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/law-of-total-probability":{"title":"Law of Total Probability","content":"\n## Definition\nIf $A$ and $B$ are [events](statistics/event.md) such that $0 \u003c \\mathbb{P}(B) \u003c 1$, then\n$$\\mathbb{P}(A) = \\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c).$$\nMore generally, if $\\lbrace B_i \\rbrace$ is a collection of events that form a [partition](statistics/partition.md) of $\\Omega$ such that $\\mathbb{P}(B_i) \u003e 0$ for at least one $i$,  then\n$$\\mathbb{P}(A) = \\sum_i \\mathbb{P}(A|B_i)\\mathbb{P}(B_i) = \\sum_i \\mathbb{P}(A \\cap B_i)$$\nfor any event $A$, by the definition of [conditional probability](statistics/conditional-probability.md).\n\n## Proof\nWe have\n$$A = A \\cap \\Omega = A \\cap (B \\cup B^c) = (A \\cap B) \\cup (A \\cap B^c),$$\nwhere $A \\cap B$ and $A \\cap B^c$ are disjoint events. Then from the [third axiom of probability](statistics/probability-measure.md) and the definition of conditional probability,\n$$\\mathbb{P}(A) = \\mathbb{P}(A \\cap B) + \\mathbb{P}(A \\cap B^c) = \\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c).$$\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/markovs-inequality":{"title":"Markov's Inequality","content":"\n## Definition\nIf $X$ be a nonnegative [random variable](statistics/random-variable.md) (i.e. $X \\geq 0$) and $a \u003e 0$. Then\n$$\\mathbb{P}(X \\geq a) \\leq \\frac{\\mathbb{E}(X)}{a}.$$\n\n## Proof\nDefine $A = \\lbrace \\omega \\in \\Omega : X(\\omega) \\geq a \\rbrace$. Then the random variable $X - a \\cdot \\mathbb{I}_A \\geq 0$, since if the outcome is in $A$, $X \\geq a$ and $a - a \\cdot \\mathbb{I}_A = 0$ implies $X \\geq a \\cdot \\mathbb{I}_A$, and if the outcome is not in $A$, $\\mathbb{I}_A = 0$ which implies $X - a \\cdot \\mathbb{I}_A = X \\geq 0$. Taking the [expectation](statistics/expectation.md) of this random variable yields\n$$\\begin{align*}\n\\mathbb{E}(X - a \\cdot \\mathbb{I}_A) \u0026\\geq 0 \\\\\n\\mathbb{E}X - a \\cdot \\mathbb{E}(\\mathbb{I}_A) \u0026\\geq 0 \\\\\n\\mathbb{E}X - a \\cdot \\mathbb{P}(A) \u0026\\geq 0 \\\\\na \\cdot \\mathbb{P}(A) \u0026\\leq \\mathbb{E}X \\\\\n\\therefore \\mathbb{P}(A) \\leq \\frac{\\mathbb{E}X}{a}.\n\\end{align*}$$\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/moment":{"title":"Moment","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the n-th *moment* of $X$ is given by $\\mathbb{E}(X^n)$.\n\nFor example, the [expectation](statistics/expectation.md) of $X$ is the first moment of $X$, and the [variance](statistics/variance.md) of $X$ is the second moment of $X$ minus the square of the first moment of $X$.\n\n\u003e [!info] Aside.\n\u003e \n\u003e There are also other types of moments. For an arbitrary random variable $X$,\n\u003e - $\\mathbb{E}((X - \\mu_X)^n)$ is called the n-th *central moment* of $X$. For example, the variance of $X$ is the second central moment of $X$.\n\u003e - $\\mathbb{E}(((X - \\mu_X)/\\sigma_X)^n)$ is called the n-th *standardized moment* of $X$. For example, the third standardized moment of $X$ is called the *skewness* of $X$.\n\u003e - $\\mathbb{E}(X(X - 1)\\cdots(X - (n - 1)))$ is called the n-th *factorial moment* of $X$.\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/partition":{"title":"Partition","content":"\n## Definition\n[Events](statistics/event.md) $A_1, A_2, \\dots$ are said to be *exhaustive* if $A_1 \\cup A_2 \\cup \\cdots = \\Omega$, that is at least one $A_i$ must occur.\n\nIf $A_1, A_2, \\dots$ are exhaustive and mutually exclusive (i.e. they cannot occur simultaneously), then they are a *partition* of $\\Omega$ and are said to partition the sample space.\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/probability-density-function":{"title":"Probability Density Function","content":"\n## Definition\nIf $X: \\Omega \\to \\mathbb{R}$ is a *continuous [random variable](statistics/random-variable.md)*, then the function $f$ such that $f(x) \\geq 0$ for all $x \\in \\Omega$ and\n$$\\mathbb{P}(x \\leq X \\leq y) = \\int_x^y f(u)du$$\nfor all $x \\leq y$, that is, the probability that $X$ takes on values in the interval $[x, y]$ is given by the area under the graph of the pdf from $x$ to $y$. It is often denoted $f_X(x).$\n\n\u003e [!warning] Note.\n\u003e \n\u003e Note that $f(x)$ is *not* a probability; it should be thought of as a *probability density*. It is not true that $f(x) = \\mathbb{P}(X = x)$ for all $x$. In fact, we have $\\mathbb{P}(X = x) = 0$ for all $x$ in the support of $X$.\n\n## Properties\nIf $X$ is a continuous random variable taking values in $\\Omega$, then\n1. $f_X(x) \\geq 0$ for all real $x$\n2. $\\int_{-\\infty}^\\infty f_X(u) du = 1$\n3. $F_X(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(u) du$, where $F_X(x)$ is the [cumulative distribution function](statistics/cumulative-distribution-function.md). Additionally, if $f_X(x)$ exists, $F'_X(x) = f_X(x)$.\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/probability-mass-function":{"title":"Probability Mass Function","content":"\n## Definition\nIf $X$ is a *discrete [random variable](statistics/random-variable.md)*, then the function\n$$f(x) = \\mathbb{P}(X = x)$$\nis the *probability (mass) function* of $X$. It is often denoted $f_X(x)$.\n\n## Properties\nIf $X$ is a discrete random variable taking values in $S$, then\n1. $f_X(x) \\geq 0$ for all real $x$\n2. $\\sum_{x\\in S} f_X(x) = 1$.\n3. $F_X(x) = \\mathbb{P}(X \\leq x) = \\sum_{y \\in S | y \\leq x} f_X(y)$, where $F_X(x)$ is the [cumulative distribution function](statistics/cumulative-distribution-function.md).","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/probability-measure":{"title":"Probability Measure","content":"\n## Definition\nThe function $\\mathbb{P}$ is called a *probability measure* if it satisfies the following properties, or *axioms*:\n1. $\\mathbb{P}(A) \\geq 0$ for all events $A$\n2. $\\mathbb{P}(\\Omega) = 1$\n3. If $A_1, A_2, \\dots$ are [mutually exclusive events](statistics/event.md), then $\\mathbb{P}(A_1 \\cup A_2 \\cup \\cdots) = \\mathbb{P}(A_1) + \\mathbb{P}(A_2) + \\cdots$\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/random-variable":{"title":"Random Variable","content":"\n## Definition\nA random variable $X$ is a function or mapping from the possible outcomes in a [sample space](statistics/sample-space.md) to numerical values, usually the real numbers.\n\nA random variable is said to be *discrete* if it takes values in (i.e. maps to) a countable set.\n\nA random variable is said to be *continuous* if it takes values in (i.e. maps to) an *interval*.\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/sample-space":{"title":"Sample Space","content":"\n## Definition\nThe set $\\Omega$ of all possible outcomes of an experiment or random trial is called the *sample space*. \n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null},"/statistics/variance":{"title":"Variance","content":"\n## Definition\nLet $X$ be an arbitrary [random variable](statistics/random-variable.md). Then the *variance* of $X$, denoted $\\text{Var}(X)$, is given by\n$$\\text{Var}(X) = \\mathbb{E}(X - \\mu_X)^2,$$ and quantities the spread of the distribution of $X$, or the variation about the mean, $\\mu_X$.\n\nThe variance may also be written as:\n$$\\text{Var}(X) = \\mathbb{E}(X - \\mu_X)^2 = \\mathbb{E}(X^2) - 2\\mu_x\\mathbb{E}X + \\mu_X^2 = \\mu_X^2 = \\mathbb{E}(X^2) - \\mu_X^2.$$\n\nThe variance of $X$ is also commonly denoted by $\\sigma_X^2$, where $\\sigma_X$ is the *standard deviation* of $X$.\n\n## Properties\nIf $X$ is any arbitrary random variable, then $\\text{Var}(aX + b) = a^2\\text{Var}(X)$ for all $a$ and $b$. \\\n**Proof.** We have\n$$\\begin{align*}\n\\text{Var}(aX + b) \u0026= \\mathbb{E}(aX + b)^2 - (\\mathbb{E}(aX + b))^2 \\\\\n\u0026= \\mathbb{E}(a^2X^2 + 2abX + b^2) - (a\\mathbb{E}X + b)^2 \\\\\n\u0026= \\mathbb{E}(a^2X^2 + 2abX + b^2) - (a^2(\\mathbb{E}X)^2 + 2ab\\mathbb{E}X + b^2) \\\\\n\u0026= a^2(\\mathbb{E}(X^2) - (\\mathbb{E}X)^2) \\\\\n\u0026= a^2\\text{Var}(X)\n\\end{align*}$$\n","lastmodified":"2023-01-01T08:34:48.449344109Z","tags":null}}